DAI-List Digest         Monday, 12 April 1993        Issue Number 116

Topics:
  DAI-List FAQ
  MACC'92 Abstracts
  Query on Status of KIF and KQML

Administrivia:
  Please send submissions to DAI-List@mcc.com.  Send other requests,
  such as changes in your e-mail address, to DAI-List-Request@mcc.com.

----------------------------------------------------------------------

From: gasser@morue.usc.edu (Les Gasser)
Subject: DAI-LIST FAQ
Date: Mon, 12 Apr 93 15:58:46 PDT

 > From: rsheldon@news.dcs.warwick.ac.uk (Richard A Sheldon)
 > Subject: Help
 > Date: 5 Apr 93 22:46:41 GMT
 > 
 > I'm looking for some advice about articles and books (articles
 > preferably) that would introduce Distributed Artificial Intelligence.
 > In particular, I'm looking for information on Speech Acts and their use
 > in DAI communication.  Any help would be gratefully achieved.
 > 
 > Richard A Sheldon
 > Department of Computer Science, Warwick University, England

Maybe it's time for some enterprising person to collect materials and
write up (and archive?) a FAQ for the DAI-LIST?

-- Les

Computational Organization Design Lab
Institute of Safety and Systems Management
USC
927 West 35th Place 
Los Angeles, CA 90089-0021 USA
Voice: 213.740.4046 
Fax:   213.740.8771
Alternate Fax:   213.740.5943
Internet: gasser@usc.edu

------------------------------

From: ishida@cslab.kecl.ntt.jp (Toru ISHIDA)
Subject: MACC'92 abstracts
Date: Mon, 12 Apr 93 08:34:08 JST

Dear colleague,

This message is a bit long, but it will help you to understand what's
going on in Japan......enjoy!

[This message is posted to the MACC (Japan), DAI (USA), and MAAMAW
(Europe) mailing lists, so some of you might receive this message again
and again.  Sorry.]

\documentstyle[12pt]{article}
\begin{document}
\title{MACC'92 Selected Papers (Abstracts)}
\author{}
\date{April 10, 1993}
\maketitle

The second workshop on Multi-Agent and Cooperative Computation (MACC)
was held from December 9 to 11, in Kobe, Japan. Twenty-eight papers
were presented and 60 people participated in discussions. The selected
fifteen papers will be published as "Multi-agent and Cooperative
Computation II", Lecture Note/Software Science, Kindai-Kagakusha, by
the end of June. The abstracts of those papers are collected below.

\begin{quote}
Contact:\\
Toru Ishida\\
MACC'92 Program Chair\\
ishida@cslab.kecl.ntt.jp
\end{quote}

\begin{enumerate}

\item
A Multi-Agent Belief Reasoning Algorithm based on a Temporal Tableau Method\\
Jun-ichi Akahani \\
NTT Communication Science Laboratories

This paper presents an algorithm for reasoning about temporal belief in
multiagent environments. Most of reasoning algorithms for agent belief
have ignored the temporal aspects of belief. However, it has become
important to deal with temporal belief since a programming paradigm for
agents has been proposed. A mechanism for reasoning about temporal
belief has been proposed, but it cannot deal with belief expressions
with logical connectives such as implications.

In this paper, we propose a reasoning algorithm for temporal belief
based on first-order logic without function symbols. We first define a
temporal logic of persistent belief in which one describes agent belief
states. We then present the temporal tableau method as a proof procedure
for the logic. The temporal tableau method is an extension of the
tableau method which is known to be sound and complete for belief
systems based on first-order logic.

\item
Mutual Reasoning based on Temporal Belief Maps\\
Hideki Isozaki\\
NTT Basic Research Laboratories

In multiagent environments, time and belief play essential roles.  Time
interacts with belief in two ways: people believe temporal facts and
belief itself changes over time.  This yields a two-dimensional map of
time with persistence along each dimension. Since beliefs may themselves
refer to other beliefs, we have to consider a statement referring to an
agent's temporal belief about another agent's temporal belief. Such a
nested temporal belief statement yields a multidimensional persistence
map.

First we discuss how to take {\it functional dependencies\/} into
account when restoring past belief from records of belief revisions.
For example, everyone believes that everyone believes that two or more
persons cannot be the U.S. president at the same time.  Therefore, if on
Christmas Eve of 1992 Mary told you that Bush was the president at that
time and that Clinton would become the president in 1993, on Christmas
of 1992 you must also have believed that Mary believed that Bush
wouldn't be the U.S. president in 1994.  We discuss ways to recall such
a past belief efficiently, and then we describe an implemented system
augmented with Prolog-like inference features.

\item
A Formalization of Action for Autonomous Agents\\
Ichiro Ohsawa and Hideyuki Nakashima\\
MITI Electrotechnical Laboratories

It is difficult to describe in advance all changes which are caused by
an action, because what kind of changes are brought about awfully depend
on the situation in which the action occurs. This problem is well-known
as the ramification problem. As a solution to the problem, we introduce
an idea of ``causal chains of primitive changes'', and formalize the
changes caused by an action as the union of the primitive changes in a
causal chain.

Our final goal is to program an autonomous agent. Thus, we assume here
that the initial primitive change in a causal chain is an internal
change, such as attempting to step ahead, of the autonomous agent.
Causality is defined as a set of causal relations, and each causal
relation represents that when a certain pattern of change emerges in a
situation of a certain type, another pattern of change also emerges at
the moment. Therefore, the causal history of primitive changes does not
affect what primitive changes are caused next.  As a result, less
definitions of causal relations are necessary to deal with many
phenomena in our framework.

Moreover, as a solution to the qualification problem -- the difficulty
in describing the condition of each action which makes it succeed -- we
extend our formalism by introducing non-monotonicity to the definition
of causal relations using the hierarchy of situation types.  That is,
the definitions of causality in a common situation do not require any
rigid specifications of their pre-situation type.  On the other hand,
the definitions of causality in an exceptional situation must specify
how the situation is exceptional.  Then, the former definitions are
effective in the common situation, while the latter inhibit the former
in the exceptional situation.

\item
A Mechanical Communication Model for Agents\\
Hideyuki Nakashima\\
MITI Electrotechnical Laboratories\\
Yasunari Harada\\
Waseda University

We are seeking to construct a software architecture under which units
(or agents) cooperate to perform a complex task.  We will describe a
mechanical (i.e., simple and not very ``intelligent'') model of
communication among agents.

We will use a formalism based on situation theory and describe how
actual dialogs are carried out with respect to the situation agents are
in.  In particular, as an essential part of dialog, our model
incorporates internal states of the agents representing the dialog
situation.  We take Japanese language as a guiding example of our
formalization, since Japanese is more situated than many other natural
languages.

\item
Messages and Protocols for Cooperative Systems Communication\\
Stephen T. C. Wong\\ 
ICOT

A cooperative problem solving {\small (CPS)} system refers to several
loosely connected and potentially heterogeneous agents that cooperate to
solve problems that require their combined expertise and resources. The
purpose of this paper is to present key features of a communication
scheme {\small COSMO} that has been used to support {\bf cooperative
problem solving} within a network of knowledge-based systems. We first
propose two key design principles of this scheme:  (1) the {\bf loose
coupling} of communication issues and knowledge representation issues,
and (2) the notion of {\bf communicative acts}.  We then work these
ideas into a set of basic components of {\small COSMO} which includes
knowledge handlers, an operation model, organizational roles, message
types, and communication protocols.

\item
Task Allocation Algorithm for Load Balancing of Multiple Autonomous
Mobile Robots\\ 
Yasushi Nakauchi, Yoshihiro Ohmori and Yuichiro Anzai\\
Keio University

The recent development of mobile robot technology gives personalized
mobile robots the possibility to work with multiple people in office,
home or other environments. We can use multiple mobile robots as a tool
for transferring physical objects.  In this paper, we propose a task
allocation algorithm that deals with physical object movements.  To show
the efficiency of this algorithm, we describe some simulation studies.
One case is for the personalized robot environment that each person
possesses his or her own robot, and another case is for the environment
where one robot is shared by some people. We compare the efficiency of
two strategies; whether robots go back to their own home position or not
after they complete their allocated tasks.  Furthermore, we have
implemented our algorithm on autonomous mobile robots {\it Einstein\/}s
we have developed.

\item
A Mechanism for Delegation among Multiagents\\
Kei Matsubayashi, Noriko Ito and Mario Tokoro\\ 
Keio University

In a multiagent environment, plans of agents sometimes partly overlap.
If agents can delegate/receive the execution of such plans (actions),
they can benefit from doing so because they do not need to execute the
overlapping actions. Despite the fact that delegating the execution of
actions is useful, few attempts have been made to incorporate such
mechanism.

In this paper, we propose a negotiation protocol for delegation based on
game theory. The agent that delegates its actions can benefit because
the cost for executing its plan is decreased. But, the agent that
receives another agent's actions will not benefit because of an increase
in cost needed for the actions. Rational agents will not participate in
negotiation if they cannot benefit from participating in it. Therefore,
an agent's attempt for delegation will be refused.

With our protocol, agents that delegate that actions must give part of
their benefit as money to the agent that receives the actions.  Then,
both agents can benefit from participating in the negotiation.  Benefit
is calculated/evaluated by each agent according to its sense of values.
As the sense of values of each agent is not necessarily the same, it is
difficult to reach a rational agreement. Even in such cases, our
protocol can reach a rational agreement according to game theory.

Also, our protocol considers the negotiation cost in the sense that
agents can smoothly reach an agreement if they have the same sense of
values.

\item
Adaptive Cooperation Schemes Coping with Dynamic Problem Space\\
Ei-Ichi Osawa\\
Sony Computer Science Laboratory Inc.

In this paper, we discuss the efficiency of adaptive cooperation schemes
that cope with changes in problem spaces, based on a pursuit game.  The
following observations are obtained.  In cases where problem solving
agents have incomplete information about the problem space because of
restricted range of perception, the performance of both autonomous agent
organizations and organizations with a fixed control structure prove
unsatisfactory.  The latter organizations are mostly bad, because the
pursuit strategy reflects only the viewpoint of a single controlling
agent.  They easily miss promising opportunities because they do not
negotiate with each other.  Negotiating agent organizations are always
successful. However, if unit communication is expensive, the total
solution cost is fairly high.  Adaptive organizations, where each agent
searches for the prey relatively autonomously with a small amount of
communication, then, at the end of the game, they change their
organization to a controlled one, perform very well even though
communication is fairly expensive.  In the early phase of cooperative
problem solving, even though each agent behaves autonomously, it works
fairly efficiently since there is a large degree of freedom of choice in
this phase . Also, autonomous agents do not require unnecessary
communication. However, when all agents come close to a final state (a
shared global goal), the freedom of choice decreases, which means that
the number of possible effective local plans decreases. Therefore, in
near final states it is much more efficient to commit agents behavior to
a single control strategy.

\item
Realtime Bidirectional Search\\
Toru Ishida\\
NTT Communication Science Laboratories

This is the first paper concerning {\em real-time bidirectional search
(RTBS)}. Unlike off-line search, real-time search interleaves both
planning and execution.  Thus, in RTBS, two problem solvers, starting
from the initial and goal states, physically move toward each other.
Since the coordination of search directions is simplified from
conventional off-line bidirectional search, these problem solvers are
expected to efficiently meet in the problem space.

To investigate the RTBS performance, two algorithms are proposed and
compared to {\em real-time unidirectional search (RTUS)} algorithms.
One is {\em centralized RTBS} which always selects the best action among
the possible moves of the two problem solvers, and the other is {\em
decoupled RTBS} where the two problem solvers independently select their
next moves. Experiments on 15-puzzles and mazes show that (1) in clear
situations, decoupled RTBS performs better, while in uncertain
situations, centralized RTBS becomes more efficient, and that (2) the
superiority or inferiority of RTUS/RTBS heavily depends on the
topography of the estimated problem spaces. It will be shown that RTBS
is more efficient than RTUS for 15-puzzles but not for mazes.

\item
A Cooperative Search Scheme for Dynamic Problems\\
Yasuhiko Kitamura, Zheng Bao Chauang, Shoji Tatsumi, Takaaki Okumoto\\
Osaka City University\\
S. Misbah Deen\\
University of Keele

The importance of building a general framework for distributed problem
solving is coming to be acknowledged.  Distributed search is one of such
frameworks and defined as to find a required path in a given graph by
cooperation of multiple agents, each of which is able to search the
graph partially.  In this paper, we propose a new cooperative search
scheme for dynamic problems where costs of the links are changeable
during the search.  To cope with the dynamic character, the agents
cooperate with each other by exchanging the cost information that they
keep. When the amount of exchanged information is large, the quality of
solution is improved, but on the other hand it raises communication
overhead, and hence it is significant to know how much information
optimizes the performance.  We developed a testbed that simulates a
communication network and applied our scheme to a routing problem which
can be viewed as a dynamic problem where the cost of a link is defined
as its communication delay.  We measured its performance according to
the amount of the cost information exchanged.

\item
On A Dynamic Method Adaptation Model by Object Cooperation\\
Yoshinori Kishimoto, Nobuto Kotaka, Shinichi Honiden\\
Information-technology Promotion Agency

A reused object and/or migrated object may need to communicate with new
partner objects, so as to fit the new operating environment.  Initiating
such communication, the so-called "acquaintance problem" occurs. We will
consider two kinds of facets of the acquaintance problem, determining
the existence of other objects (object names), and establishing
communications with the found object. For the former case, it is
necessary to check the required function with the provided function. For
the latter, it is necessary to adjust messages with methods according to
the formats of the two objects.

We propose a dynamic object method adaptation model OMEGA based on a
cooperation of agents, as the first step toward a dynamic object
adjustment model. An agent consists of an object and a metaobject that
has the function to adapt its method by a reflection mechanism. Each
agent keeps information acquired during past adaptation processes,
besides method specifications given by its designer. An agent can offer
this information to other agents during method adaptation on demand.

In this paper, we describe the content of information kept by each agent
and the interaction strategy for agents to adapt methods.

\item
Meta-Level Control Decision for Autonomous Robot\\
with Multiple Reasoning Schemes\\
Tetsuo Sawaragi, Osamu Katai and Sosuke Iwai\\
Kyoto University

The intelligent agent has to coordinate a number of heterogeneous
activities that include not only physical sensing and/or actuating
activities but also deliberative activities. The latter includes an
activity to select the most preferred reasoning scheme out of available
multiple schemes, and to evaluate whether it is worthwhile or not to
execute the reasoned result.  Moreover, these activities usually contain
uncertainties in some ways and are performed under conditions of scarce
computational resources. In this paper, we investigate into a formally
rigorous techniques based on decision-theoretic principles that address
the problem of bounding the amount of reasoning cost under resource
constraints and uncertainty. We derive a set of optimal decision
policies that may be used to decide on which reasoning scheme to use and
where should they be used. The decision model, that is represented by an
influence diagram, takes into account all sources of uncertainty and
risk preferences to derive at the optimal decision policy by
deliberating on the trade-off between the value of the information
potentially available and the computational cost.

\item
Self-Organization of Communication in Artificial Organisms\\
Norihiko Ono and Adel T.Rahmani\\
University of Tokushima

In this paper, an application of learning classifier systems is
presented. An artificial multiagent environment has been designed. Mate
finding problem, a learning task inspired by nature, is considered which
needs cooperation by two distinct artificial organisms to achieve the
goal. The main feature of our system is existence of two parallel
learning subsystems which have to agree on a common communication
protocol to succeed in accomplishing the task. Apart from standard
learning algorithms, a unification mechanism has been introduced to
encourage coordinated behavior among the organisms belonging to the same
class. Experimental results are presented which demonstrate the
effectiveness of this mechanism and the learning capabilities of
classifier systems.

\item
Emergent Planning: Planning without Planner Based on
Dynamical Constraint Programming\\
Katashi Nagao\\
Sony Computer Science Laboratory Inc.\\
K\^oiti Hasida\\
Electrotechnical Laboratory\\
Takashi Miyata\\
University of Tokyo

We discuss planning implemented in a computational architecture called
{\em dynamical constraint programming}.  This architecture is totally
constraint-based, with the semantics of constraints defined as a sort of
dynamics.  The degree of violation is captured in terms of {\em
potential energy}, which is a real-valued function of the state of the
constraint.  The constraint is thus provided with a fine-grained
declarative semantics.  Control schemes for analog and symbolic
inferences are obtained on the basis of the energy minimization
principle.  Information processing occurs as dynamical interaction, so
that tight feedback loops are established among diverse sorts of
information.  Planning is emergent and does not need any specific
procedure (i.e., a planner).  Control of information processing for
action selection (i.e., planning) emerges from the dynamical control of
computation.  The dynamical state and topology of constraints change in
accordance with the interaction between agents and their ever-changing
environments.  Shifting between reactivity and deliberativity is also an
emergent property of this dynamical control.

\item
Cognition Model with Multi-Agent System \\
Hiroshi G. Okuno \\
University of Tokyo

We propose a new computation model called {\it Emergent Computation
Model\ } for cognitive modeling.  Our motivation is based on the
observation that complete recognition of speech or complete
understanding of speech act is not always needed in human
communications.  Cognition is considered as solving reverse problems
such as reverse optics and reverse acoustics.  A set of constraints are
required to solve reverse problems.  Introducing constraints leads to an
active attitude towards perceptions.  Listening/looking is more active
than hearing/seeing. The proposed model consists of a set of competent
agents each of which may have its own goal.  The system has no global
goal and some goals competes against each other.  Competent agents can
activate or inhibit other agents in the sense of subsumption
architecture proposed by Brooks and agents are fired by spreading
activation in the sense of connectionist computation proposed by Maes.
The behavior of the system is not determined but emerges according to
the input, the situation, and activation/inhibition parameter from goals
of each agent.

Emergent Computation Model not only explains various aspects of human
communications but also gives the framework for cognitive systems.  It
is applied to Auditory Scene Analysis and Spontaneous Spoken Language
Understanding System to explain the mechanism of cocktail party problem
and focus selection of attentions.

\end{enumerate}
\end{document}

------------------------------

From: gray@orpheus.cas.american.edu (Michael Gray)
Subject: Re:  sharing of knowledge bases
Date: Mon, 12 Apr 93 14:36:02 EDT

>[[I suggest the KIF and KQML efforts (AI Magazine, Fall 1991) - Huhns]]

Does anyone know what's happening in these efforts?  Any publications
after the AI Magazine?

Michael Gray
CSIS Department
American University
Washington, DC  20016-8116
gray@orpheus.cas.american.edu
(202) 885-1430

------------------------------

End of DAI-List Digest Issue #116
*********************************
