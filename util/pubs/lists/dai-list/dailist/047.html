DAI-List Digest         Wednesday, 14 August 1991        Issue Number 47

Topics:
  DPS vs. MA, (cont.)
  Cooperation, Trust
  Overview of MAAMAW-91 Workshop

Please send submissions to DAI-List@mcc.com.  Send other requests,
such as changes in your e-mail address, to DAI-List-Request@mcc.com.
------------------------------------------------------------------------

From: Jeff Rosenschein <jeff@cs.huji.ac.il>
Date: Tue, 13 Aug 91 11:45:19 +0300
Subject: DPS vs. MA, again

My perspective on the difference between DPS and MA systems is that in
DPS, the system designer can *depend* on agents helping one another with
information, actions, etc. if that would be an effective way to build
the desired system, while in Multiagent research, the system designer
simply cannot *depend* on agents helping one another.

It's more a matter of fundamental overall control of the interaction
environment, rather than the details of who has what goals, or how
helpful the agents are. In a DPS system, the agents might not help each
other, but that was at some level the designer's choice. In a MA system,
the agents might help each other (and might even have identical goals),
but at some level that was not the designer's choice, it was not really
under his control.

In other words, I believe the distinction is in the options available to
the agent builder at the design stage, not (necessarily) in the agent's
behavior at run-time.  You could happen upon a group of agents
interacting, and from their goals, beliefs, and behavior, not know
whether or not they were centrally designed.

It's my hope that the MA perspective helps builders of DPS systems
consider more autonomous, "competitive" attitudes for their centrally
designed agents---when that ends up being an effective way to build the
kinds of systems they want to build.

--Jeff
------------------------------------------------------------------------

Date: Tue, 13 Aug 91 11:55:02 BST
From: canon.co.uk!steve (Steve Marsh)
Subject: Cooperation, Trust

A couple of thoughts about what's been said in the DAI-List recently...

>  The actual technique is to consider a utility function for any
>arbitrary coalition's action, consider how the coalition's payoff is
>divided among members (we use the Shapley value to divide payoffs
>among coalition members), then allow each agent to selfish join
>whatever coalition he wants (including, of course, the coalition where
>he is the only member). Perhaps this mixing of selfish and cooperative
>coalition formation is a pertinent example of Ed Durfee's message
>about the DPS-MA spectrum: "Most interesting problems have agents that
>are partially adversarial and partially cooperative all at the same
>time."

This technique struck me as extremely useful for many areas in this
field, not least where the concept of a clique or a group was concerned.
The idea of a utility function covers it quite well - in a multiagent
world, what kind of payoffs can we (as a group) obtain from letting you
(as an individual) join and help us? Is more of a payoff attainable if,
for example, you are a group or clique yourself (also, if 'you' are a
group, will we be more inclined to 'trust' you since you already trust
each other?) Cooperation to me is a function of more than one variable,
not least:
  - Additional benefit to group of 'letting' another individual/group
join
  - Cost of letting individual (or group) join
  - Benefit to potential joiner ("do I want to join this group?") - This
is, if I read it right, what your work with Ran Levy concentrates on?
  - Benefits (to group and individual) of any previous coalitions (Thus
giving us a need for the concept of identity of individuals and a memory
of some sort)

I'd be interested to hear how different payoff functions, etc. drive the
agents (pursuers) in terms of cooperation.

Steve
------------------------------------------------------------------------

From: Anand Rao <anand@aaii.oz.au>
Date: Wed, 14 Aug 91 17:02:46 EST
Subject: Overview of MAAMAW-91 Workshop

For those of you in the community who did not make it to 
the MAAMAW-91 workshop here is a brief workshop report:

         MAAMAW-91 held at Kaiserslautern from August 5-7

The Third European Workshop on Modeling Autonomous Agents and
Multi-Agent Worlds was held in a wonderful place called Kaiserslautern
in Germany.  The conference attendance was limited to around 60
participants, which facilitated good interaction.  There were 13 paper
presentations, 4 invited talks, 1 panel discussion, a poster session,
and 5 entrants for the Multi-Agent Olympics (system demonstrations).

The papers presented at the workshop seemed to fall under three
categories:  (A) top-down design of various aspects of multiagent
systems, (B) bottom-up emergent behaviour of multiagent systems, and
(C) bridging the gap between approaches (A) and (B).  A majority of the
papers (8) were in Category A indicating that the community at large is
still pre-occupied with top-down design.  However, some interesting
papers were presented in Categories B (3) and C (2).

Out of the 8 papers in Category A, 4 were formal/semiformal approaches
to different aspects of MA systems.  The paper by Chang & Woo discusses
a protocol for negotiation based on speech act theory.  Rao, Georgeff &
Sonenberg discuss notions of social plans and joint intentions.  Osawa
and Tokoro provide a model for collaborative planning.  Castlefranchi,
Miceli & Cesta formalize the notion of social dependence.

The remaining four papers in Category A provide architectures for
designing MA systems.  Three of these are general-purpose architectures,
while the paper by Boissier and Demazeau provides a DAI architecture for
general purpose vision systems. Burmeister & Sundermeyer give an
architecture for problem-solving where intentions and perception play
important roles. The paper by Ferguson discusses a three-layered
architecture and an experimental testbed. Collinot & Hayes-Roth descibe
a satisficing algorithm for control and analyse the performance of this
algorithm.

In Category B, the paper by Gambardella & Haex discusses simulation of
physical objects, where the global physical behaviour emerges from the
interaction of agents. Drogoul & Dubreuil provide an interesting
solution to the N-puzzle problem using the eco-problem-solving or
emergent model.  Levy & Rosenschein give a game-theoretic solution to
the pursuit problem.

Papers by Wavish and Kiss & Reichgelt try to integrate both the top-down
and bottom-up approaches. Wavish models symbolic behaviours and shows
how emergent behaviours can be integrated with them to provide a rich
model of behaviours. Kiss and Reichgelt use concepts from physical
dynamics to give a semantics of desires.

The panel discussion was on the dynamics of knowledge and organisation
in MA systems.  Numaoka gave a presentation on dynamic organisations,
Dragoni on belief revision in MA context and Jennings on the
formalisation of joint responsibility.  Interesting discussions followed
the presentations and Werner summarised the different issues involved in
MA systems.

The first invited talk was by Rosenschein & Kraus on focal points and
attempts to formalize such a notion. Kiss talked about a layered
architecture for the design of MA systems. The third invited talk was by
Latombe who gave an overview of robot motion planning.  Gasser argued
for a bottom-up design of MA systems in his talk on why DAI systems work
and why they don't work.

The five entrants for the MA olympics included (a) simulation of an
insect (using subsumption architecture) from U. of Hamburg, (b)
Distributed ATMS by DFKI, (c) Emergent behaviour in a "Sheepdog"
Simulation by Philips Research Labs, (d) Eco-problem-solving model of
N-puzzle by U. of Paris & CERT-ONERA, and (e) MA system based on OPS5.
The best prize was awarded to Drogul & Dubreuil for their demonstration
of N-puzzle.

On the whole the program chairmen Demazeau and Werner & local organizers
Steiner and Muller had put together a wonderful workshop.  The next
workshop will be held near Rome, and Castelfranchi and Werner will be
the program chairmen.

Anand S. Rao
AAII
1 Grattan Street
Carlton
Victoria 3053 Australia



