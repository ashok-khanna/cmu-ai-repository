Subject: Reference list
From:    Jacob Sparre Andersen <sparre@connect.nbi.dk>
Date:    Thu, 18 Nov 93 16:13:05 +0700

We're writing a paper on learning strategic games with neural nets and 
other optimization methods. 
We've collected some references, but we hope that we can get some help
improving our reference list.

Regards, 
         Jacob Sparre Andersen and Peer Sommerlund

 
Here's our list of references (some not complete):

   Justin A. Boyan (1992): "Modular Neural Networks for Learning
        Context-Dependent Game Strategies", Department of Engineering and
        Computer Laboratory, University of Cambridge, 1992, Cambridge, England

   Bernd Bruegmann (1993): "Monte Carlo Go", unpublished?

   Herbert Enderton (1989?): "The Golem Go Program"

   B. Freisleben (1992): "Teaching a Neural Network to Play GO-MOKU,"
        Artificial Neural Networks 2, proceedings of ICANN '92, editors: I.
        Aleksander and J. Taylor, pp. 1659-1662, Elsevier Science Publishers,
        1992

   W.T.Katz and S.P.Pham (1991): "Experience-Based Learning Experiments using
        Go-moku", Proc. of the 1991 IEEE International Conference on Systems,
        Man, and Cybernetics, 2: 1405-1410, October 1991.

   M. Kohle & F. Schonbauer (19??): "Experience gained with a neural network
        that learns to play bridge", Proc. of the 5th Austrian Artificial
        Intelligence meeting, pp. 224-229.

   Kai-Fu Lee and Sanjoy Mahajan (1988): "A Pattern Classification Approach to
        Evaluation Function Learning", Artificial Intelligence, 1988, vol 36,
        pp. 1-25.

   Barney Pell (1992?): ""
        Pell has done some work in machine learning for GO.
        Article available by ftp.

   A.L. Samuel (1959): "Some studies in machine learning using the game of
        checkers", IBM journal of Research and Development, vol 3, nr. 3, pp.
        210-229, 1959.

   A.L. Samuel (1967): "Some studies in machine learning using the game of
        checkers 2 - recent progress", IBM journal of Research and Development,
        vol 11, nr. 6, pp.  601-616, 1967.

   David Stoutamire (19??):
        has written a thesis on machine learning applied to Go.

   G. Tesauro (1989): "Connectionist learning of expert preferences by
        comparison training", Advances in NIPS 1, 99-106 1989

   G. Tesauro & T.J. Sejnowski (1989): "A Parallel Network that learns to play
        Backgammon", Artificial Intelligence, vol 39, pp. 357-390, 1989.

   G. Tesauro & T.J. Sejnowski (1990): "Neurogammon: A Neural
        Network Backgammon Program", IJCNN Proceedings, vol 3, pp. 33-39, 1990.

   In Machine Learning is this article, in which he comments on
        temporal difference learning (i.e. training a net from scratch by
        playing a copy of itself). The program he develops is called
        "TD-gammon":

   G. Tesauro (1991): "Practical Issues in Temporal Difference
        Learning", IBM Research Report RC17223(#76307 submitted) 9/30/91; see
        also the special issue on Reinforcement Learning of the Machine
        Learning Journal 1992, where it also appears.

   He Yo, Zhen Xianjun, Ye Yizheng, Li Zhongrong (1990): "Knowledge
        acquisition and reasoning based on neural networks - the research of a
        bridge bidding system", INNC '90, Paris, vol 1, pp. 416-423.

   The annual computer olympiad involves tournaments in a variety of
        games. These publications contain a wealth of interesting articles:

      Heuristic Programming in Artificial Intelligence -
              the first computer olympiad
           D.N.L. Levy & D.F. Beal eds.
           Ellis Horwood ltd, 1989.

      Heuristic Programming in Artificial Intelligence 2 -
              the second computer olympiad
           D.N.L. Levy & D.F. Beal eds.
           Ellis Horwood, 1991.

      Heuristic Programming in Artificial Intelligence 3 -
              the third computer olympiad
           H.J. van den Herik & L.V. Allis eds.
           Ellis Horwood, 1992.
