From dfe@aifbbach.aifb.uni-karlsruhe.de Fri Feb 11 11:58:40 EST 1994
Article: 20639 of comp.ai
Xref: glinda.oz.cs.cmu.edu comp.ai:20639
Path: honeydew.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!news.msfc.nasa.gov!sol.ctr.columbia.edu!xlink.net!rz.uni-karlsruhe.de!aifbbach!dfe
From: dfe@aifbbach.aifb.uni-karlsruhe.de (Dieter Fensel)
Newsgroups: comp.ai
Subject: Familiarization Workshop Knowledge Level Models of Machine Learning
Date: 11 Feb 1994 12:45:29 GMT
Organization: AIFB, Universitaet Karlsruhe, Germany
Lines: 203
Sender: dfe@aifbbach (Dieter Fensel)
Distribution: world
Message-ID: <2jful9$ql8@nz12.rz.uni-karlsruhe.de>
NNTP-Posting-Host: aifbbach.aifb.uni-karlsruhe.de
Mime-Version: 1.0
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: 8bit

%% -*-LaTeX-*- file created by Walter Van de Velde
%% Artificial Intelligence Laboratory
%% Vrije Universiteit Brussel
%% Pleinlaan 2, B-1050 Brussels, Belgium
%% Email: walter@arti.vub.ac.be
%% Wed Jan  5 14:47:37 1994

\documentstyle{article} 
\title{Familiarization Workshop\\knowledge level models of machine
  learning} 
\author{Walter Van de Velde}
\date{January 22nd, 1994}
\begin{document}
\maketitle
\begin{abstract}
  This is an invitation to participate in, and submit to a workshop to
  be organized in the context of the second MLNet familiarization
  workshop, 6-8 april 1994, Catania, Italy. It provides the following
  information: title, topic description, relevance, potential,
  workshop format, organizing committee and time table.
\end{abstract}

\section{Title}

Knowledge Level Models of Machine Learning

\section{Topic Description}

The aim of this workshop is to discuss knowledge level modeling
applied to machine learning systems and algorithms.

An important distinction in current expert systems research is the one
between knowledge level and symbol level \cite{Newell:82a}. Systems
can be described at either of these levels. Briefly stated, a
knowledge level description emphasizes the knowledge contents of a
system (e.g.  goals, actions and knowledge used in a rational way)
whereas the symbol level describes its computational realization (in
terms of representations and inference mechanisms). There is a
consensus that modeling at the knowledge level is a useful
intermediate step in the development of an expert system
\cite{SteelsMcDermott:93}. So called second generation expert systems
explicitly incorporate aspects of their knowledge level structure,
resulting in potential advantages for knowledge acquisition, design,
implementation, explanation and maintenance (see \cite{David:93a} for
an overview on the state of the art). The technical goal is to
construct generic components which can be reused and refined as
needed, guided by features of the domain and the task instead of by
engineering considerations.

This workshop investigates the results on describing learning systems
at the knowledge level, hoping to gain some of the same advantages.
Although the earliest attempts to do this \cite{Dietterich:86} failed
to lead to useful results, later efforts provided interesting insights
\cite{Flann:89a}. Maybe a more important reason for the exploration of
the knowledge level of learning systems is that the notion of
knowledge level itself, as it is currently used in expert systems
research, is no longer equivalent to Newell's \cite{VandeVelde:93a}.
Currently used models are considerably more manageable, structured
and, in a sense, more engineering oriented.  Knowledge level analysis
of learning systems can directly benefit from the developments in
knowledge modeling that are currently taking place (see e.g.
\cite{Klinker:93a} for recent work). Moreover the knowledge level
analysis of machine learning systems can be done directly in available
environments allowing for the easy integration with problem solving or
knowledge acquisition systems.

Note that the relevance of the knowledge level ideas to machine
learning is broader than what is described here (e.g., learning of
knowledge level models). To keep the present workshop relatively
focussed It is suggested to stick closely to the main topic: knowledge
level modeling of machine learning.

\section{Relevance}

The topic of this workshop is relevant for several reasons:

\begin{itemize}
\item It provides insights into essential features, differences and
  similarities of machine learning algorithms
\item It contributes to the flexible and problem specific
  configuration of learning systems
\item It contributes to integrating learning into performing systems
\item It contributes to the bridge between ML and KA
\item It supports the exchange and reuse of results in machine
  learning.\footnote{From the answers to the questionnaire organized by
    the VUB AI-Lab at IJCAI and the previous MLNet workshop, the
    problems in exchange and reuse of systems emerged as one of the
    key bottlenecks in current research practice.}
\end{itemize}

We are looking forward to a strong interest and participation in this
workshop:

\begin{itemize}
\item Europe has a strong tradition in knowledge level modeling, with
  the developments of such methodologies as KADS and Components of
  Expertise, and of languages and environments for constructing
  knowledge level models (KARL, MoMo, KresT, FML, and so on) and large
  scale projects in this direction such as MLT and parts of KADS-II.
\item Several papers have been seen on knowledge level modeling of
  learning (e.g. at the previous familiarization workshop in the
  section on integrated architectures, in the last KADS user group
  meeting, in the European Workshop on Case-Based Reasoning, and so
  forth). The workshop is a good opportunity to bring these results
  together.
\item The workshop works on the bridge between knowledge acquisition
  and machine learning, using concepts of the KA community to
  understand results in the ML community.
\end{itemize}

\section{Workshop Format}

The workshop will consist of presentations of papers and work in small
subgroups to develop knowledge models of learning in specific
frameworks. Participants are encouraged to bring software that can be
used for the interactive construction, configuration and execution of
knowledge level models of machine learning algorithms. These
environments exist (at least KresT, the CommonKADS workbench and NOOS
can be provided) and a result of the workshop will be their
application in a real experiment of exchange, reuse and configuration
of machine learning systems and algorithms.

In addition the workshop will issue a call for knowledge level models
of machine learning systems and algorithms to be input in a common
library. Assistance will be provided so that all the participants in
ECML or the workshops have a chance to contribute to this effort. This
aspect is depending on the availability of some computing
infrastructure at the site of the conference, an issue which will be
treated in due course.

\section{Organizing Committee}

Agnar Aamodt (University of Trondheim, Norway)\\
Dieter Fensel (University of Karlsruhe, Germany)\\
Enric Plaza (IIIA, Blanes, Catalunya, Spain)\\
Walter Van de Velde (VUB AI-Lab, Brussels, Belgium)\\
Maarten Van Someren (SWI, Universtiy of Amsterdam, The Netherlands)

\section{Timetable}

\begin{description}
\item[March 1:] submission deadline
\item[March 15:] notification of acceptance (allows for early
  registration fee)
\item[March 30:] copy for distribution due. Only participants that
  are actually registered will be included in the proceedings.
\item[April 9-10:] workshop
\end{description}

Please send your submission before March 1 to the address below. LaTeX
submissions by email are strongly encouraged.

\begin{verbatim}
Walter Van de Velde
Artificial Intelligence Laboratory           Tel: +32 2 641 37 00
Vrije Universiteit Brussel                   Fax: +32 2 641 37 29
Pleinlaan 2, B-1050 Brussels         Email: walter@arti.vub.ac.be
\end{verbatim}

\begin{thebibliography}{}

\bibitem[David et~al., 1993]{David:93a}
David, J.-M., Krivine, J.-P., and Simmons, R. (Eds.).  (1993).
\newblock {\em Second Generation Expert Systems}.
\newblock Springer Verlag, Berlin.

\bibitem[Dietterich, 1986]{Dietterich:86}
Dietterich, T.~G. (1986).
\newblock Learning at the knowledge level.
\newblock {\em Machine Learning}, 1, 287--316.

\bibitem[Flann and Dietterich, 1989]{Flann:89a}
Flann, N. and Dietterich, T. (1989).
\newblock A study of explanation-based methods for inductive learning.
\newblock {\em Machine Learning}, 4(2), 187--226.

\bibitem[Klinker, 1993]{Klinker:93a}
Klinker, G. (Ed.).  (1993).
\newblock {\em Special Issue: Current issues in knowledge modeling}, volume~5
  of {\em Knowledge Acquisition}.
\newblock Academic Press.

\bibitem[Newell, 1982]{Newell:82a}
Newell, A. (1982).
\newblock The knowledge level.
\newblock {\em Artificial Intelligence}, 18, 87--127.

\bibitem[Steels and McDermott, 1993]{SteelsMcDermott:93}
Steels, L. and McDermott, J. (Eds.).  (1993).
\newblock {\em The Knowledge Level in Expert Systems. Conversations and
  Commentary}.
\newblock Academic Press, Boston, MA.

\bibitem[{Van de Velde}, 1993]{VandeVelde:93a}
{Van de Velde}, W. (1993).
\newblock Issues in knowledge level modeling.
\newblock In J.-M.~David, J.-P.~K. and Simmons, R. (Eds.). , {\em Second
  Generation Expert Systems}. Springer Verlag, Berlin.

\end{thebibliography}

\end{document}



