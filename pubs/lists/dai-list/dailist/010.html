DAI-List Digest         Tuesday, 12 June 1990           Issue Number 10

Topics:
 Submission Info for 10th International Workshop on DAI
 Is Consensus a DAI Problem?

Please send submissions to DAI-List@mcc.com.  Send other requests,
such as changes in your e-mail address, to DAI-List-Request@mcc.com.
------------------------------------------------------------------------

Subject: Submission Info for 10th International Workshop on DAI
Date: Tue, 12 June 90 16:07 CDT
From: Michael N. Huhns <huhns@mcc.com>

                        Call for Participation
10th AAAI International Workshop on Distributed Artificial Intelligence

                          The Flying L Ranch
                            Bandera, Texas (near San antonio)
                          October 23-27, 1990

Papers are expected to be extended abstracts, 5-7 pages in length
(approximately 2500 words), not counting the bibliography, and hardcopy
only (3 copies).  If your abstract is accepted, you may submit a more
complete version (up to 20 pages) for inclusion in the informal
proceedings and for possible publication in a special issue of IEEE
Systems, Man, and Cybernetics being prepared by Ed Durfee, or in DAI
Volume III.  Please submit your papers to

Michael N. Huhns (chairman)
MCC
3500 West Balcones Center Drive
Austin, TX   78759-6509
(512) 338-3651 or <huhns@mcc.com>

DATES:

Deadline for submission of papers (3 copies, please):  July 2, 1990.

Notification of acceptance:                            August 7, 1990.

Final papers due (for distribution at the Workshop):   October 1, 1990.

------------------------------------------------------------------------

Subject: Is Consensus a DAI Problem?
Date: Mon, 11 Jun 90 16:10 PDT
From: Robin Hanson <Hanson@CHARON.arc.nasa.gov>

Consider the following "Consensus" PROBLEM:

GIVEN a group of agents who
  1) can vary radically in style of and capacity for thought
  2) have access to different relevant information (which can overlap)
  3) do not trust or respect each other (have hidden internal states)
  4) are autonomous, and so can't be easily coerced 
And GIVEN a question where we might expect the agents to (internally)
disagree

What "social" mechanism can we set up (at a small or negligible cost)
SO THAT the agents quickly form a public consensus belief on this
question SUCH THAT it is clearly in the self-interest of each agent to
participate in the process and ACT as if they agreed with the
consensus?

(I.e. outsiders could not tell by examining the various agent's actions
that they intended to disagree substantially with the consensus.)

I believe I have an answer to this problem, at least for the case where,
with enough effort and analysis and data, the agents would all
eventually come to agree on what the answer to the question is.

Note the following are NOT solutions:
1) Big Brother puts a gun to their head, and forces them to act as if
they agree.
2) Big Daddy offers them each $1M to act as if agree (costs too much).
3) They vote and majority wins.  (Why should they act as if agree with
this?)
4) They exchange all relevant information.  (They might lie, costs too
much.)

I don't presently work in DAI--do those of you who do think this problem
is relevant for DAI work?  Is a result like this publishable?

I am willing to post my answer, but would like to hear what other people
think first.

Robin Hanson  hanson@charon.arc.nasa.gov (or hanson@ptolemy.arc.nasa.gov)
415-604-3361  MS244-17, NASA Ames Research Center, Moffett Field, CA 94035
415-651-7483  47164 Male Terrace, Fremont, CA  94539-7921 



