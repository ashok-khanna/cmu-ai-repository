%!
%%BoundingBox: (atend)
%%Pages: (atend)
%%DocumentFonts: (atend)
%%EndComments
%
% FrameMaker PostScript Prolog 3.0, for use with FrameMaker 3.0
% Copyright (c) 1986,87,89,90,91 by Frame Technology Corporation.
% All rights reserved.
%
% Known Problems:
%	Due to bugs in Transcript, the 'PS-Adobe-' is omitted from line 1
/FMversion (3.0) def 
% Set up Color vs. Black-and-White
	/FMPrintInColor systemdict /colorimage known
		systemdict /currentcolortransfer known or def
% Uncomment this line to force b&w on color printer
%   /FMPrintInColor false def
/FrameDict 195 dict def 
systemdict /errordict known not {/errordict 10 dict def
		errordict /rangecheck {stop} put} if
% The readline in 23.0 doesn't recognize cr's as nl's on AppleTalk
FrameDict /tmprangecheck errordict /rangecheck get put 
errordict /rangecheck {FrameDict /bug true put} put 
FrameDict /bug false put 
mark 
% Some PS machines read past the CR, so keep the following 3 lines together!
currentfile 5 string readline
00
0000000000
cleartomark 
errordict /rangecheck FrameDict /tmprangecheck get put 
FrameDict /bug get { 
	/readline {
		/gstring exch def
		/gfile exch def
		/gindex 0 def
		{
			gfile read pop 
			dup 10 eq {exit} if 
			dup 13 eq {exit} if 
			gstring exch gindex exch put 
			/gindex gindex 1 add def 
		} loop
		pop 
		gstring 0 gindex getinterval true 
		} def
	} if
/FMVERSION {
	FMversion ne {
		/Times-Roman findfont 18 scalefont setfont
		100 100 moveto
		(FrameMaker version does not match postscript_prolog!)
		dup =
		show showpage
		} if
	} def 
/FMLOCAL {
	FrameDict begin
	0 def 
	end 
	} def 
	/gstring FMLOCAL
	/gfile FMLOCAL
	/gindex FMLOCAL
	/orgxfer FMLOCAL
	/orgproc FMLOCAL
	/organgle FMLOCAL
	/orgfreq FMLOCAL
	/yscale FMLOCAL
	/xscale FMLOCAL
	/manualfeed FMLOCAL
	/paperheight FMLOCAL
	/paperwidth FMLOCAL
/FMDOCUMENT { 
	array /FMfonts exch def 
	/#copies exch def
	FrameDict begin
	0 ne dup {setmanualfeed} if
	/manualfeed exch def
	/paperheight exch def
	/paperwidth exch def
	/yscale exch def
	/xscale exch def
	currenttransfer cvlit /orgxfer exch def
	currentscreen cvlit /orgproc exch def
	/organgle exch def /orgfreq exch def
	setpapername 
	manualfeed {true} {papersize} ifelse 
	{manualpapersize} {false} ifelse 
	{desperatepapersize} if
	end 
	} def 
	/pagesave FMLOCAL
	/orgmatrix FMLOCAL
	/landscape FMLOCAL
/FMBEGINPAGE { 
	FrameDict begin 
	/pagesave save def
	3.86 setmiterlimit
	/landscape exch 0 ne def
	landscape { 
		90 rotate 0 exch neg translate pop 
		}
		{pop pop}
		ifelse
	xscale yscale scale
	/orgmatrix matrix def
	gsave 
	} def 
/FMENDPAGE {
	grestore 
	pagesave restore
	end 
	showpage
	} def 
/FMFONTDEFINE { 
	FrameDict begin
	findfont 
	ReEncode 
	1 index exch 
	definefont 
	FMfonts 3 1 roll 
	put
	end 
	} def 
/FMFILLS {
	FrameDict begin
	array /fillvals exch def
	end 
	} def 
/FMFILL {
	FrameDict begin
	 fillvals 3 1 roll put
	end 
	} def 
/FMNORMALIZEGRAPHICS { 
	newpath
	0.0 0.0 moveto
	1 setlinewidth
	0 setlinecap
	0 0 0 sethsbcolor
	0 setgray 
	} bind def
	/fx FMLOCAL
	/fy FMLOCAL
	/fh FMLOCAL
	/fw FMLOCAL
	/llx FMLOCAL
	/lly FMLOCAL
	/urx FMLOCAL
	/ury FMLOCAL
/FMBEGINEPSF { 
	end 
	/FMEPSF save def 
	/showpage {} def 
	FMNORMALIZEGRAPHICS 
	[/fy /fx /fh /fw /ury /urx /lly /llx] {exch def} forall 
	fx fy translate 
	rotate
	fw urx llx sub div fh ury lly sub div scale 
	llx neg lly neg translate 
	} bind def
/FMENDEPSF {
	FMEPSF restore
	FrameDict begin 
	} bind def
FrameDict begin 
/setmanualfeed {
%%BeginFeature *ManualFeed True
	 statusdict /manualfeed true put
%%EndFeature
	} def
/max {2 copy lt {exch} if pop} bind def
/min {2 copy gt {exch} if pop} bind def
/inch {72 mul} def
/pagedimen { 
	paperheight sub abs 16 lt exch 
	paperwidth sub abs 16 lt and
	{/papername exch def} {pop} ifelse
	} def
	/papersizedict FMLOCAL
/setpapername { 
	/papersizedict 14 dict def 
	papersizedict begin
	/papername /unknown def 
		/Letter 8.5 inch 11.0 inch pagedimen
		/LetterSmall 7.68 inch 10.16 inch pagedimen
		/Tabloid 11.0 inch 17.0 inch pagedimen
		/Ledger 17.0 inch 11.0 inch pagedimen
		/Legal 8.5 inch 14.0 inch pagedimen
		/Statement 5.5 inch 8.5 inch pagedimen
		/Executive 7.5 inch 10.0 inch pagedimen
		/A3 11.69 inch 16.5 inch pagedimen
		/A4 8.26 inch 11.69 inch pagedimen
		/A4Small 7.47 inch 10.85 inch pagedimen
		/B4 10.125 inch 14.33 inch pagedimen
		/B5 7.16 inch 10.125 inch pagedimen
	end
	} def
/papersize {
	papersizedict begin
		/Letter {lettertray letter} def
		/LetterSmall {lettertray lettersmall} def
		/Tabloid {11x17tray 11x17} def
		/Ledger {ledgertray ledger} def
		/Legal {legaltray legal} def
		/Statement {statementtray statement} def
		/Executive {executivetray executive} def
		/A3 {a3tray a3} def
		/A4 {a4tray a4} def
		/A4Small {a4tray a4small} def
		/B4 {b4tray b4} def
		/B5 {b5tray b5} def
		/unknown {unknown} def
	papersizedict dup papername known {papername} {/unknown} ifelse get
	end
	/FMdicttop countdictstack 1 add def 
	statusdict begin stopped end 
	countdictstack -1 FMdicttop {pop end} for 
	} def
/manualpapersize {
	papersizedict begin
		/Letter {letter} def
		/LetterSmall {lettersmall} def
		/Tabloid {11x17} def
		/Ledger {ledger} def
		/Legal {legal} def
		/Statement {statement} def
		/Executive {executive} def
		/A3 {a3} def
		/A4 {a4} def
		/A4Small {a4small} def
		/B4 {b4} def
		/B5 {b5} def
		/unknown {unknown} def
	papersizedict dup papername known {papername} {/unknown} ifelse get
	end
	stopped 
	} def
/desperatepapersize {
	statusdict /setpageparams known
		{
		paperwidth paperheight 0 1 
		statusdict begin
		{setpageparams} stopped pop 
		end
		} if
	} def
/savematrix {
	orgmatrix currentmatrix pop
	} bind def
/restorematrix {
	orgmatrix setmatrix
	} bind def
/dmatrix matrix def
/dpi    72 0 dmatrix defaultmatrix dtransform
    dup mul exch   dup mul add   sqrt def
/freq dpi 18.75 div 8 div round dup 0 eq {pop 1} if 8 mul dpi exch div def
/sangle 1 0 dmatrix defaultmatrix dtransform exch atan def
/DiacriticEncoding [
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /space /exclam /quotedbl
/numbersign /dollar /percent /ampersand /quotesingle /parenleft
/parenright /asterisk /plus /comma /hyphen /period /slash /zero /one
/two /three /four /five /six /seven /eight /nine /colon /semicolon
/less /equal /greater /question /at /A /B /C /D /E /F /G /H /I /J /K
/L /M /N /O /P /Q /R /S /T /U /V /W /X /Y /Z /bracketleft /backslash
/bracketright /asciicircum /underscore /grave /a /b /c /d /e /f /g /h
/i /j /k /l /m /n /o /p /q /r /s /t /u /v /w /x /y /z /braceleft /bar
/braceright /asciitilde /.notdef /Adieresis /Aring /Ccedilla /Eacute
/Ntilde /Odieresis /Udieresis /aacute /agrave /acircumflex /adieresis
/atilde /aring /ccedilla /eacute /egrave /ecircumflex /edieresis
/iacute /igrave /icircumflex /idieresis /ntilde /oacute /ograve
/ocircumflex /odieresis /otilde /uacute /ugrave /ucircumflex
/udieresis /dagger /.notdef /cent /sterling /section /bullet
/paragraph /germandbls /registered /copyright /trademark /acute
/dieresis /.notdef /AE /Oslash /.notdef /.notdef /.notdef /.notdef
/yen /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/ordfeminine /ordmasculine /.notdef /ae /oslash /questiondown
/exclamdown /logicalnot /.notdef /florin /.notdef /.notdef
/guillemotleft /guillemotright /ellipsis /.notdef /Agrave /Atilde
/Otilde /OE /oe /endash /emdash /quotedblleft /quotedblright
/quoteleft /quoteright /.notdef /.notdef /ydieresis /Ydieresis
/fraction /currency /guilsinglleft /guilsinglright /fi /fl /daggerdbl
/periodcentered /quotesinglbase /quotedblbase /perthousand
/Acircumflex /Ecircumflex /Aacute /Edieresis /Egrave /Iacute
/Icircumflex /Idieresis /Igrave /Oacute /Ocircumflex /.notdef /Ograve
/Uacute /Ucircumflex /Ugrave /dotlessi /circumflex /tilde /macron
/breve /dotaccent /ring /cedilla /hungarumlaut /ogonek /caron
] def
/ReEncode { 
	dup 
	length 
	dict begin 
	{
	1 index /FID ne 
		{def} 
		{pop pop} ifelse 
	} forall 
	0 eq {/Encoding DiacriticEncoding def} if 
	currentdict 
	end 
	} bind def
/graymode true def
	/bwidth FMLOCAL
	/bpside FMLOCAL
	/bstring FMLOCAL
	/onbits FMLOCAL
	/offbits FMLOCAL
	/xindex FMLOCAL
	/yindex FMLOCAL
	/x FMLOCAL
	/y FMLOCAL
/setpattern {
	 /bwidth  exch def
	 /bpside  exch def
	 /bstring exch def
	 /onbits 0 def  /offbits 0 def
	 freq sangle landscape {90 add} if 
		{/y exch def
		 /x exch def
		 /xindex x 1 add 2 div bpside mul cvi def
		 /yindex y 1 add 2 div bpside mul cvi def
		 bstring yindex bwidth mul xindex 8 idiv add get
		 1 7 xindex 8 mod sub bitshift and 0 ne
		 {/onbits  onbits  1 add def 1}
		 {/offbits offbits 1 add def 0}
		 ifelse
		}
		setscreen
	 {} settransfer
	 offbits offbits onbits add div FMsetgray
	/graymode false def
	} bind def
/grayness {
	FMsetgray
	graymode not {
		/graymode true def
		orgxfer cvx settransfer
		orgfreq organgle orgproc cvx setscreen
		} if
	} bind def
	/HUE FMLOCAL
	/SAT FMLOCAL
	/BRIGHT FMLOCAL
	/Colors FMLOCAL
FMPrintInColor 
	
	{
	/HUE 0 def
	/SAT 0 def
	/BRIGHT 0 def
	% array of arrays Hue and Sat values for the separations [HUE BRIGHT]
	/Colors   
	[[0    0  ]    % black
	 [0    0  ]    % white
	 [0.00 1.0]    % red
	 [0.37 1.0]    % green
	 [0.60 1.0]    % blue
	 [0.50 1.0]    % cyan
	 [0.83 1.0]    % magenta
	 [0.16 1.0]    % comment / yellow
	 ] def
      
	/BEGINBITMAPCOLOR { 
		BITMAPCOLOR} def
	/BEGINBITMAPCOLORc { 
		BITMAPCOLORc} def
	/BEGINBITMAPTRUECOLOR { 
		BITMAPTRUECOLOR } def
	/BEGINBITMAPTRUECOLORc { 
		BITMAPTRUECOLORc } def
	/K { 
		Colors exch get dup
		0 get /HUE exch store 
		1 get /BRIGHT exch store
		  HUE 0 eq BRIGHT 0 eq and
			{1.0 SAT sub setgray}
			{HUE SAT BRIGHT sethsbcolor} 
		  ifelse
		} def
	/FMsetgray { 
		/SAT exch 1.0 exch sub store 
		  HUE 0 eq BRIGHT 0 eq and
			{1.0 SAT sub setgray}
			{HUE SAT BRIGHT sethsbcolor} 
		  ifelse
		} bind def
	}
	
	{
	/BEGINBITMAPCOLOR { 
		BITMAPGRAY} def
	/BEGINBITMAPCOLORc { 
		BITMAPGRAYc} def
	/BEGINBITMAPTRUECOLOR { 
		BITMAPTRUEGRAY } def
	/BEGINBITMAPTRUECOLORc { 
		BITMAPTRUEGRAYc } def
	/FMsetgray {setgray} bind def
	/K { 
		pop
		} def
	}
ifelse
/normalize {
	transform round exch round exch itransform
	} bind def
/dnormalize {
	dtransform round exch round exch idtransform
	} bind def
/lnormalize { 
	0 dtransform exch cvi 2 idiv 2 mul 1 add exch idtransform pop
	} bind def
/H { 
	lnormalize setlinewidth
	} bind def
/Z {
	setlinecap
	} bind def
	/fillvals FMLOCAL
/X { 
	fillvals exch get
	dup type /stringtype eq
	{8 1 setpattern} 
	{grayness}
	ifelse
	} bind def
/V { 
	gsave eofill grestore
	} bind def
/N { 
	stroke
	} bind def
/M {newpath moveto} bind def
/E {lineto} bind def
/D {curveto} bind def
/O {closepath} bind def
	/n FMLOCAL
/L { 
 	/n exch def
	newpath
	normalize
	moveto 
	2 1 n {pop normalize lineto} for
	} bind def
/Y { 
	L 
	closepath
	} bind def
	/x1 FMLOCAL
	/x2 FMLOCAL
	/y1 FMLOCAL
	/y2 FMLOCAL
	/rad FMLOCAL
/R { 
	/y2 exch def
	/x2 exch def
	/y1 exch def
	/x1 exch def
	x1 y1
	x2 y1
	x2 y2
	x1 y2
	4 Y 
	} bind def
/RR { 
	/rad exch def
	normalize
	/y2 exch def
	/x2 exch def
	normalize
	/y1 exch def
	/x1 exch def
	newpath
	x1 y1 rad add moveto
	x1 y2 x2 y2 rad arcto
	x2 y2 x2 y1 rad arcto
	x2 y1 x1 y1 rad arcto
	x1 y1 x1 y2 rad arcto
	closepath
	16 {pop} repeat
	} bind def
/C { 
	grestore
	gsave
	R 
	clip
	} bind def
	/FMpointsize FMLOCAL
/F { 
	FMfonts exch get
	FMpointsize scalefont
	setfont
	} bind def
/Q { 
	/FMpointsize exch def
	F 
	} bind def
/T { 
	moveto show
	} bind def
/RF { 
	rotate
	0 ne {-1 1 scale} if
	} bind def
/TF { 
	gsave
	moveto 
	RF
	show
	grestore
	} bind def
/P { 
	moveto
	0 32 3 2 roll widthshow
	} bind def
/PF { 
	gsave
	moveto 
	RF
	0 32 3 2 roll widthshow
	grestore
	} bind def
/S { 
	moveto
	0 exch ashow
	} bind def
/SF { 
	gsave
	moveto
	RF
	0 exch ashow
	grestore
	} bind def
/B { 
	moveto
	0 32 4 2 roll 0 exch awidthshow
	} bind def
/BF { 
	gsave
	moveto
	RF
	0 32 4 2 roll 0 exch awidthshow
	grestore
	} bind def
/G { 
	gsave
	newpath
	normalize translate 0.0 0.0 moveto 
	dnormalize scale 
	0.0 0.0 1.0 5 3 roll arc 
	closepath fill
	grestore
	} bind def
/A { 
	gsave
	savematrix
	newpath
	2 index 2 div add exch 3 index 2 div sub exch 
	normalize 2 index 2 div sub exch 3 index 2 div add exch 
	translate 
	scale 
	0.0 0.0 1.0 5 3 roll arc 
	restorematrix
	stroke
	grestore
	} bind def
	/x FMLOCAL
	/y FMLOCAL
	/w FMLOCAL
	/h FMLOCAL
	/xx FMLOCAL
	/yy FMLOCAL
	/ww FMLOCAL
	/hh FMLOCAL
	/FMsaveobject FMLOCAL
	/FMoptop FMLOCAL
	/FMdicttop FMLOCAL
/BEGINPRINTCODE { 
	/FMdicttop countdictstack 1 add def 
	/FMoptop count 4 sub def 
	/FMsaveobject save def
	userdict begin 
	/showpage {} def 
	FMNORMALIZEGRAPHICS 
	3 index neg 3 index neg translate
	} bind def
/ENDPRINTCODE {
	count -1 FMoptop {pop pop} for 
	countdictstack -1 FMdicttop {pop end} for 
	FMsaveobject restore 
	} bind def
/gn { 
	0 
	{	46 mul 
		cf read pop 
		32 sub 
		dup 46 lt {exit} if 
		46 sub add 
		} loop
	add 
	} bind def
	/str FMLOCAL
/cfs { 
	/str sl string def 
	0 1 sl 1 sub {str exch val put} for 
	str def 
	} bind def
/ic [ 
	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0223
	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0223
	0
	{0 hx} {1 hx} {2 hx} {3 hx} {4 hx} {5 hx} {6 hx} {7 hx} {8 hx} {9 hx}
	{10 hx} {11 hx} {12 hx} {13 hx} {14 hx} {15 hx} {16 hx} {17 hx} {18 hx}
	{19 hx} {gn hx} {0} {1} {2} {3} {4} {5} {6} {7} {8} {9} {10} {11} {12}
	{13} {14} {15} {16} {17} {18} {19} {gn} {0 wh} {1 wh} {2 wh} {3 wh}
	{4 wh} {5 wh} {6 wh} {7 wh} {8 wh} {9 wh} {10 wh} {11 wh} {12 wh}
	{13 wh} {14 wh} {gn wh} {0 bl} {1 bl} {2 bl} {3 bl} {4 bl} {5 bl} {6 bl}
	{7 bl} {8 bl} {9 bl} {10 bl} {11 bl} {12 bl} {13 bl} {14 bl} {gn bl}
	{0 fl} {1 fl} {2 fl} {3 fl} {4 fl} {5 fl} {6 fl} {7 fl} {8 fl} {9 fl}
	{10 fl} {11 fl} {12 fl} {13 fl} {14 fl} {gn fl}
	] def
	/sl FMLOCAL
	/val FMLOCAL
	/ws FMLOCAL
	/im FMLOCAL
	/bs FMLOCAL
	/cs FMLOCAL
	/len FMLOCAL
	/pos FMLOCAL
/ms { 
	/sl exch def 
	/val 255 def 
	/ws cfs 
	/im cfs 
	/val 0 def 
	/bs cfs 
	/cs cfs 
	} bind def
400 ms 
/ip { 
	is 
	0 
	cf cs readline pop 
	{	ic exch get exec 
		add 
		} forall 
	pop 
	
	} bind def
/wh { 
	/len exch def 
	/pos exch def 
	ws 0 len getinterval im pos len getinterval copy pop
	pos len 
	} bind def
/bl { 
	/len exch def 
	/pos exch def 
	bs 0 len getinterval im pos len getinterval copy pop
	pos len 
	} bind def
/s1 1 string def
/fl { 
	/len exch def 
	/pos exch def 
	/val cf s1 readhexstring pop 0 get def
	pos 1 pos len add 1 sub {im exch val put} for
	pos len 
	} bind def
/hx { 
	3 copy getinterval 
	cf exch readhexstring pop pop 
	} bind def
	/h FMLOCAL
	/w FMLOCAL
	/d FMLOCAL
	/lb FMLOCAL
	/bitmapsave FMLOCAL
	/is FMLOCAL
	/cf FMLOCAL
/wbytes { 
	dup 
	8 eq {pop} {1 eq {7 add 8 idiv} {3 add 4 idiv} ifelse} ifelse
	} bind def
/BEGINBITMAPBWc { 
	1 {} COMMONBITMAPc
	} bind def
/BEGINBITMAPGRAYc { 
	8 {} COMMONBITMAPc
	} bind def
/BEGINBITMAP2BITc { 
	2 {} COMMONBITMAPc
	} bind def
/COMMONBITMAPc { 
	/r exch def
	/d exch def
	gsave
	translate rotate scale /h exch def /w exch def
	/lb w d wbytes def 
	sl lb lt {lb ms} if 
	/bitmapsave save def 
	r                    
	/is im 0 lb getinterval def 
	ws 0 lb getinterval is copy pop 
	/cf currentfile def 
	w h d [w 0 0 h neg 0 h] 
	{ip} image 
	bitmapsave restore 
	grestore
	} bind def
/BEGINBITMAPBW { 
	1 {} COMMONBITMAP
	} bind def
/BEGINBITMAPGRAY { 
	8 {} COMMONBITMAP
	} bind def
/BEGINBITMAP2BIT { 
	2 {} COMMONBITMAP
	} bind def
/COMMONBITMAP { 
	/r exch def
	/d exch def
	gsave
	translate rotate scale /h exch def /w exch def
	/bitmapsave save def 
	r                    
	/is w d wbytes string def
	/cf currentfile def 
	w h d [w 0 0 h neg 0 h] 
	{cf is readhexstring pop} image
	bitmapsave restore 
	grestore
	} bind def
	/proc1 FMLOCAL
	/proc2 FMLOCAL
	/newproc FMLOCAL
/Fmcc {
    /proc2 exch cvlit def
    /proc1 exch cvlit def
    /newproc proc1 length proc2 length add array def
    newproc 0 proc1 putinterval
    newproc proc1 length proc2 putinterval
    newproc cvx
} bind def
/ngrayt 256 array def
/nredt 256 array def
/nbluet 256 array def
/ngreent 256 array def
	/gryt FMLOCAL
	/blut FMLOCAL
	/grnt FMLOCAL
	/redt FMLOCAL
	/indx FMLOCAL
	/cynu FMLOCAL
	/magu FMLOCAL
	/yelu FMLOCAL
	/k FMLOCAL
	/u FMLOCAL
/colorsetup {
	currentcolortransfer
	/gryt exch def
	/blut exch def
	/grnt exch def
	/redt exch def
	0 1 255 {
		/indx exch def
		/cynu 1 red indx get 255 div sub def
		/magu 1 green indx get 255 div sub def
		/yelu 1 blue indx get 255 div sub def
		/k cynu magu min yelu min def
		/u k currentundercolorremoval exec def
		nredt indx 1 0 cynu u sub max sub redt exec put
		ngreent indx 1 0 magu u sub max sub grnt exec put
		nbluet indx 1 0 yelu u sub max sub blut exec put
		ngrayt indx 1 k currentblackgeneration exec sub gryt exec put
	} for
	{255 mul cvi nredt exch get}
	{255 mul cvi ngreent exch get}
	{255 mul cvi nbluet exch get}
	{255 mul cvi ngrayt exch get}
	setcolortransfer
	{pop 0} setundercolorremoval
	{} setblackgeneration
	} bind def
	/tran FMLOCAL
/fakecolorsetup {
	/tran 256 string def
	0 1 255 {/indx exch def 
		tran indx
		red indx get 77 mul
		green indx get 151 mul
		blue indx get 28 mul
		add add 256 idiv put} for
	currenttransfer
	{255 mul cvi tran exch get 255.0 div}
	exch Fmcc settransfer
} bind def
/BITMAPCOLOR { 
	/d 8 def
	gsave
	translate rotate scale /h exch def /w exch def
	/bitmapsave save def 
	colorsetup
	/is w d wbytes string def
	/cf currentfile def 
	w h d [w 0 0 h neg 0 h] 
	{cf is readhexstring pop} {is} {is} true 3 colorimage 
	bitmapsave restore 
	grestore
	} bind def
/BITMAPCOLORc { 
	/d 8 def
	gsave
	translate rotate scale /h exch def /w exch def
	/lb w d wbytes def 
	sl lb lt {lb ms} if 
	/bitmapsave save def 
	colorsetup
	/is im 0 lb getinterval def 
	ws 0 lb getinterval is copy pop 
	/cf currentfile def 
	w h d [w 0 0 h neg 0 h] 
	{ip} {is} {is} true 3 colorimage
	bitmapsave restore 
	grestore
	} bind def
/BITMAPTRUECOLORc { 
        gsave
        translate rotate scale /h exch def /w exch def
        /bitmapsave save def 
        
        /is w string def
        
        ws 0 w getinterval is copy pop 
        /cf currentfile def 
        w h 8 [w 0 0 h neg 0 h] 
        {ip} {gip} {bip} true 3 colorimage
        bitmapsave restore 
        grestore
        } bind def
/BITMAPTRUECOLOR { 
        gsave
        translate rotate scale /h exch def /w exch def
        /bitmapsave save def 
        /is w string def
        /gis w string def
        /bis w string def
        /cf currentfile def 
        w h 8 [w 0 0 h neg 0 h] 
        { cf is readhexstring pop } 
        { cf gis readhexstring pop } 
        { cf bis readhexstring pop } 
        true 3 colorimage 
        bitmapsave restore 
        grestore
        } bind def
/BITMAPTRUEGRAYc { 
        gsave
        translate rotate scale /h exch def /w exch def
        /bitmapsave save def 
        
        /is w string def
        
        ws 0 w getinterval is copy pop 
        /cf currentfile def 
        w h 8 [w 0 0 h neg 0 h] 
        {ip gip bip w gray} image
        bitmapsave restore 
        grestore
        } bind def
/ww FMLOCAL
/r FMLOCAL
/g FMLOCAL
/b FMLOCAL
/i FMLOCAL
/gray { 
        /ww exch def
        /b exch def
        /g exch def
        /r exch def
        0 1 ww 1 sub { /i exch def r i get .299 mul g i get .587 mul
			b i get .114 mul add add r i 3 -1 roll floor cvi put } for
        r
        } bind def
/BITMAPTRUEGRAY { 
        gsave
        translate rotate scale /h exch def /w exch def
        /bitmapsave save def 
        /is w string def
        /gis w string def
        /bis w string def
        /cf currentfile def 
        w h 8 [w 0 0 h neg 0 h] 
        { cf is readhexstring pop 
          cf gis readhexstring pop 
          cf bis readhexstring pop w gray}  image
        bitmapsave restore 
        grestore
        } bind def
/BITMAPGRAY { 
	8 {fakecolorsetup} COMMONBITMAP
	} bind def
/BITMAPGRAYc { 
	8 {fakecolorsetup} COMMONBITMAPc
	} bind def
/ENDBITMAP {
	} bind def
end 
	/ALDsave FMLOCAL
	/ALDmatrix matrix def ALDmatrix currentmatrix pop
/StartALD {
	/ALDsave save def
	 savematrix
	 ALDmatrix setmatrix
	} bind def
/InALD {
	 restorematrix
	} bind def
/DoneALD {
	 ALDsave restore
	} bind def
%%EndProlog
%%BeginSetup
(3.0) FMVERSION
1 1 612 792 0 1 19 FMDOCUMENT
0 0 /Times-Roman FMFONTDEFINE
1 0 /Times-Bold FMFONTDEFINE
2 0 /Times-Italic FMFONTDEFINE
3 1 /Symbol FMFONTDEFINE
4 0 /Courier FMFONTDEFINE
32 FMFILLS
0 0 FMFILL
1 .1 FMFILL
2 .3 FMFILL
3 .5 FMFILL
4 .7 FMFILL
5 .9 FMFILL
6 .97 FMFILL
7 1 FMFILL
8 <0f1e3c78f0e1c387> FMFILL
9 <0f87c3e1f0783c1e> FMFILL
10 <cccccccccccccccc> FMFILL
11 <ffff0000ffff0000> FMFILL
12 <8142241818244281> FMFILL
13 <03060c183060c081> FMFILL
14 <8040201008040201> FMFILL
16 1 FMFILL
17 .9 FMFILL
18 .7 FMFILL
19 .5 FMFILL
20 .3 FMFILL
21 .1 FMFILL
22 0.03 FMFILL
23 0 FMFILL
24 <f0e1c3870f1e3c78> FMFILL
25 <f0783c1e0f87c3e1> FMFILL
26 <3333333333333333> FMFILL
27 <0000ffff0000ffff> FMFILL
28 <7ebddbe7e7dbbd7e> FMFILL
29 <fcf9f3e7cf9f3f7e> FMFILL
30 <7fbfdfeff7fbfdfe> FMFILL
%%EndSetup
%%Page: "25" 1
%%BeginPaperSize: Letter
%%EndPaperSize
612 792 0 FMBEGINPAGE
0 8 Q
0 X
0 K
0.4 (Journal of Artificial Intelligence Research 1 \0501993\051 25-32) 86 742.5 S
0.4 (Submitted 6/91; published 9/91) 405.38 742.5 S
0.4 (\251 1993 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.) 86 57.67 S
1 14 Q
(Minimizing Con\337icts: A Heuristic Repair Method for) 142.66 678.83 T
(Constraint-Satisfaction and Scheduling Pr) 154.61 658.83 T
(oblems) 407.41 658.83 T
1 11 Q
0.28 (Steven Minton) 86 628.83 S
0 8 Q
0.2 (MINTON@PTOLEMY.ARC.NASA.GOV) 373.99 628.83 S
1 11 Q
0.28 (Andy Philips) 86 615.83 S
0 8 Q
0.2 (PHILIPS@PTOLEMY.ARC.NASA.GOV) 376.44 615.83 S
2 11 Q
(Sterling Federal Systems, AI Research Branch, Mail Stop: 269-2,) 86 602.83 T
(NASA Ames Research Center, Moffett Field, CA 94035, U.S.A.) 86 589.83 T
1 F
0.28 (Mark D. Johnston) 86 572.83 S
0 8 Q
0.2 (JOHNSTON@STSCI.EDU) 425.53 572.83 S
2 11 Q
(Space Telescope Science Institute, 3700 San Martin Drive,) 86 559.83 T
(Baltimore, MD 21218, U.S.A.) 86 546.83 T
1 F
0.28 (Philip Laird) 86 529.83 S
0 8 Q
0.2 (LAIRD@PTOLEMY.ARC.NASA.GOV) 381.74 529.83 S
2 11 Q
(NASA Ames Research Center, AI Research Branch, Mail Stop: 269-2,) 86 516.83 T
(Moffett Field, CA 94035, U.S.A.) 86 503.83 T
86 456.17 518 474.17 C
86 456.17 518 474.17 R
7 X
0 K
V
86 465.17 518 474.17 R
V
1 12 Q
0 X
(Abstract) 279.69 466.17 T
0 0 612 792 C
0 10 Q
0 X
0 K
0.19 0.4 (This paper describes a simple heuristic approach to solving large-scale constraint sat-) 122 449.5 B
3.05 0.4 (isfaction and scheduling problems. In this approach one starts with an inconsistent) 104 437.5 B
0.62 0.4 (assignment for a set of variables and searches through the space of possible repairs. The) 104 425.5 B
-0.71 0.4 (search can be guided by a value-ordering heuristic, the) 104 413.5 B
2 F
-0.71 0.4 (min-conflicts heuristic) 340.91 413.5 B
0 F
-0.71 0.4 (, that attempts) 439.07 413.5 B
0.2 0.4 (to minimize the number of constraint violations after each step. The heuristic can be used) 104 401.5 B
1.15 0.4 (with a variety of different search strategies. We demonstrate empirically that on the) 104 389.5 B
1.15 0.4 (-) 496.27 389.5 B
0.55 0.4 (queens problem, a technique based on this approach performs orders of magnitude better) 104 377.5 B
0.04 0.4 (than traditional backtracking techniques. We also describe a scheduling application where) 104 365.5 B
-0.43 0.4 (the approach has been used successfully. A theoretical analysis is presented both to explain) 104 353.5 B
-0.25 0.4 (why this method works well on certain types of problems and to predict when it is likely to) 104 341.5 B
0.4 (be most effective.) 104 329.5 S
1 12 Q
(1.) 86 304.17 T
(Intr) 104 304.17 T
(oduction) 124.44 304.17 T
0 11 Q
0.29 0.28 (One of the most promising general approaches for solving combinatorial search problems is) 86 285.83 B
1.26 0.28 (to generate an initial, suboptimal solution and then to apply local) 86 272.83 B
2 F
1.26 0.28 (r) 406.62 272.83 B
1.26 0.28 (epair) 410.76 272.83 B
0 F
1.26 0.28 ( heuristics. T) 435.33 272.83 B
1.26 0.28 (ech-) 497.99 272.83 B
-0.03 0.28 (niques based on this approach have met with empirical success on many combinatorial prob-) 86 259.83 B
5.78 0.28 (lems, including the traveling salesman and graph partitioning problems \050Johnson,) 86 246.83 B
0.47 0.28 (Papadimitrou, & Y) 86 233.83 B
0.47 0.28 (annakakis, 1988\051. Such techniques also have a long tradition in AI, most) 174.44 233.83 B
1.2 0.28 (notably in problem-solving systems that operate by debugging initial solutions \050Simmons,) 86 220.83 B
-0.08 0.28 (1988; Sussman, 1975\051. In this paper) 86 207.83 B
-0.08 0.28 (, we describe how this idea can be extended to constraint) 253.19 207.83 B
0.28 (satisfaction problems \050CSPs\051 in a natural manner) 86 194.83 S
0.28 (.) 314.02 194.83 S
-0.25 0.28 (Most of the previous work on CSP algorithms has assumed a \322constructive\323 backtracking) 104 181.83 B
1 0.28 (approach in which a partial assignment to the variables is incrementally extended. In con-) 86 168.83 B
0.53 0.28 (trast, our method \050Minton, Johnston, Philips, & Laird, 1990\051 creates a complete, but incon-) 86 155.83 B
2.04 0.28 (sistent assignment and then repairs constraint violations until a consistent assignment is) 86 142.83 B
0.28 (achieved. The method is guided by a simple ordering heuristic for repairing constraint viola-) 86 129.83 S
0.73 0.28 (tions: identify a variable that is currently in con\337ict and select a new value that minimizes) 86 116.83 B
0.28 (the number of outstanding constraint violations.) 86 103.83 S
489.77 386.65 496.27 396.66 C
2 9 Q
0 X
0 K
(n) 490.77 389.5 T
0 0 612 792 C
FMENDPAGE
%%EndPage: "25" 2
%%Page: "26" 2
612 792 0 FMBEGINPAGE
0 10 Q
0 X
0 K
0.5 (M) 224.33 745.33 S
0 7 Q
0.35 (INTON) 233.71 745.33 S
0 10 Q
0.5 (, P) 257.2 745.33 S
0 7 Q
0.35 (HILIPS) 269.25 745.33 S
0 10 Q
0.5 (, J) 293.09 745.33 S
0 7 Q
0.35 (OHNSTON) 303.48 745.33 S
0 10 Q
0.5 (, & L) 339.31 745.33 S
0 7 Q
0.35 (AIRD) 363.19 745.33 S
0 10 Q
0.5 (26) 297.5 57.33 S
0 11 Q
0.26 0.28 (W) 104 690.33 B
0.26 0.28 (e present empirical evidence showing that on some standard problems our approach is) 113.77 690.33 B
-0.25 0.28 (considerably more ef) 86 677.33 B
-0.25 0.28 (\336cient than traditional constructive backtracking methods. For example,) 183.54 677.33 B
1.73 0.28 (on the) 86 664.33 B
1.73 0.28 (-queens problem, our methods quickly \336nds solutions to the one million queens) 127.79 664.33 B
1.38 0.28 (problem. W) 86 651.33 B
1.38 0.28 (e ar) 141.73 651.33 B
1.38 0.28 (gue that the reason that repair) 160.18 651.33 B
1.38 0.28 (-based methods can outperform constructive) 305.66 651.33 B
0.12 0.28 (methods is because a complete assignment can be more informative in guiding search than a) 86 638.33 B
1.34 0.28 (partial assignment. However) 86 625.33 B
1.34 0.28 (, the utility of the extra information is domain dependent. T) 221.67 625.33 B
1.34 0.28 (o) 512.23 625.33 B
1.88 0.28 (help clarify the nature of this potential advantage, we present a theoretical analysis that) 86 612.33 B
1.39 0.28 (describes how various problem characteristics may af) 86 599.33 B
1.39 0.28 (fect the performance of the method.) 343.99 599.33 B
1.11 0.28 (This analysis shows, for example, how the \322distance'' between the current assignment and) 86 586.33 B
0.49 0.28 (solution \050in terms of the minimum number of repairs that are required\051 af) 86 573.33 B
0.49 0.28 (fects the expected) 433.36 573.33 B
0.28 (utility of the heuristic.) 86 560.33 S
0.08 0.28 (The work described in this paper was inspired by a surprisingly ef) 104 547.33 B
0.08 0.28 (fective neural network) 412.95 547.33 B
1.3 0.28 (developed by T) 86 534.33 B
1.3 0.28 (arif) 160.04 534.33 B
1.3 0.28 (f and Johnston \050Adopt & Johnston, 1990: Johnston & T) 176.19 534.33 B
1.3 0.28 (arif) 445.6 534.33 B
1.3 0.28 (f, 1989\051 for) 461.75 534.33 B
1.73 0.28 (scheduling astronomical observations on the Hobble Space T) 86 521.33 B
1.73 0.28 (elescope. Our heuristic CSP) 382.11 521.33 B
-0.15 0.28 (method was distilled from an analysis of the network. In the process of carrying out the anal-) 86 508.33 B
0.14 0.28 (ysis, we discovered that the ef) 86 495.33 B
0.14 0.28 (fectiveness of the network has little to do with its connections) 227.44 495.33 B
0.81 0.28 (implementation. Furthermore, the ideas employed in the network can be implemented very) 86 482.33 B
1.55 0.28 (ef) 86 469.33 B
1.55 0.28 (\336ciently within a symbolic CSP framework. The symbolic implementation is extremely) 94.89 469.33 B
1.21 0.28 (simple. It also has the advantage that several dif) 86 456.33 B
1.21 0.28 (ferent search strategies can be employed,) 320.07 456.33 B
-0 0.28 (although we have found that hill-climbing methods are particularly well-suited for the appli-) 86 443.33 B
0.28 (cations that we have investigated.) 86 430.33 S
0.06 0.28 (W) 104 417.33 B
0.06 0.28 (e begin the paper with a brief review of T) 113.77 417.33 B
0.06 0.28 (arif) 307.88 417.33 B
0.06 0.28 (f and Johnston's neural network, and then) 324.03 417.33 B
1.82 0.28 (describe our symbolic method for heuristic repair) 86 404.33 B
1.82 0.28 (. Following this, we describe empirical) 327.01 404.33 B
0.49 0.28 (results with the) 86 391.33 B
0.49 0.28 (-queens problem, graph-colorability problems and the Hobble Space T) 168.53 391.33 B
0.49 0.28 (ele-) 500.43 391.33 B
1.31 0.28 (scope scheduling application. Finally) 86 378.33 B
1.31 0.28 (, we consider a theoretical model identifying general) 262.96 378.33 B
0.75 0.28 (problem characteristics that in\337uence the performance of the method. W) 86 365.33 B
0.75 0.28 (e include a second) 429.67 365.33 B
0.28 (gratuitous citation to ourselves to illustrate a short citation \050Minton et al., 1990\051.) 86 352.33 S
1 12 Q
(2.) 86 326.67 T
(Pr) 104 326.67 T
(evious W) 116.44 326.67 T
(ork: The GDS Network) 162.76 326.67 T
0 11 Q
0.58 0.28 (By almost any measure, the Hubble Space T) 86 308.33 B
0.58 0.28 (elescope scheduling problem is a complex task) 295.86 308.33 B
0.9 0.28 (\050Johnston, 1987; Airdrop, 1989\051.   Between ten thousand and thirty thousand astronomical) 86 295.33 B
0.68 0.28 (observations per year must be scheduled, subject to a great variety of constraints including) 86 282.33 B
0.82 0.28 (power restrictions, observation priorities, time-dependent orbital characteristics, movement) 86 269.33 B
0.42 0.28 (of astronomical bodies, stray light sources, etc. Because the telescope is an extremely valu-) 86 256.33 B
1.54 0.28 (able resource with a limited lifetime, ef) 86 243.33 B
1.54 0.28 (\336cient scheduling is a critical concern. An initial) 279.32 243.33 B
0.28 0.28 (scheduling system, developed using traditional programming methods, highlighted the dif) 86 230.33 B
0.28 0.28 (\336-) 507.41 230.33 B
0.46 0.28 (culty of the problem; it was estimated that it would take over three weeks for the system to) 86 217.33 B
0.02 0.28 (schedule one week of observations. As described in section 4, this problem was remedied by) 86 204.33 B
0.43 0.28 (dividing the problem into a long-term scheduling problem and a short the development of a) 86 191.33 B
0.63 0.28 (successful constraint-based system to augment the initial system. The constraint-based sys-) 86 178.33 B
0.12 0.28 (tem produces a high-level schedule and the original system then derives a detailed schedule.) 86 165.33 B
0.29 0.28 (A more successful constraint-based system was then developed to augment the original sys-) 86 152.34 B
0.08 0.28 (tem. At the heart of the constraint-based system is a neural network developed by Adorf and) 86 139.34 B
1.37 0.28 (Johnston, the Guarded Discrete Stochastic \050GDS\051 network, which searches for a schedule) 86 126.34 B
0.28 (\050Adorf & Johnston, 1990: Johnston & Adorf, 1989\051.) 86 113.34 S
2.89 0.28 (From a computational point of view the network is interesting because Adorf and) 104 100.34 B
0.27 0.28 (Johnston found that it performs well on a variety of tasks, in addition to the space telescope) 86 87.34 B
121.29 661.48 127.79 671.49 C
2 9 Q
0 X
0 K
(n) 122.29 664.33 T
0 0 612 792 C
162.03 388.48 168.53 398.49 C
2 9 Q
0 X
0 K
(n) 163.04 391.33 T
0 0 612 792 C
FMENDPAGE
%%EndPage: "26" 3
%%Page: "27" 3
612 792 0 FMBEGINPAGE
0 10 Q
0 X
0 K
0.5 (M) 191.15 746.33 S
0 7 Q
0.35 (INIMIZING) 200.53 746.33 S
0 10 Q
0.5 ( C) 238.61 746.33 S
0 7 Q
0.35 (ONFLICTS:) 248.78 746.33 S
0 10 Q
0.5 ( A H) 287.26 746.33 S
0 7 Q
0.35 (EURISTIC) 308.69 746.33 S
0 10 Q
0.5 ( R) 342.94 746.33 S
0 7 Q
0.35 (EPAIR) 353.1 746.33 S
0 10 Q
0.5 ( M) 375.04 746.33 S
0 7 Q
0.35 (ETHOD) 387.42 746.33 S
0 10 Q
0.5 (27) 296.5 57.33 S
0 11 Q
0.15 0.28 (scheduling problem. For example, the network performs signi\336cantly better on the) 86 690.33 B
0.15 0.28 (-queens) 481.63 690.33 B
0.12 0.28 (problem than methods that were previously developed. The) 86 677.33 B
0.12 0.28 (-queens problem requires plac-) 373.03 677.33 B
0.02 0.28 (ing) 86 664.33 B
0.02 0.28 ( queens on an) 110.41 664.33 B
0.02 0.28 ( chessboard so that no two queens share a row) 203.77 664.33 B
0.02 0.28 (, column or diagonal.) 418.49 664.33 B
0.42 0.28 (The network has been used to solve problems of up to 1024 queens, whereas most heuristic) 86 651.33 B
2.41 0.28 (backtracking methods encounter dif) 86 638.33 B
2.41 0.28 (\336culties with problems one-tenth that size \050Stone &) 260.11 638.33 B
0.28 (Stone, 1987\051.) 86 625.33 S
0.59 0.28 (The GDS network is a modi\336ed Hop\336eld network \050Hop\336eld, 1982\051. In a standard Hop-) 104 612.33 B
-0.22 0.28 (\336eld network, all connections between neurons are symmetric. In the GDS network, the main) 86 599.33 B
0.32 0.28 (network is coupled asymmetrically to an auxiliary network of guard neurons which restricts) 86 586.33 B
1.36 0.28 (the con\336gurations that the network can assume. This modi\336cation enables the network to) 86 573.33 B
0.89 0.28 (rapidly \336nd a solution for many problems, even when the network is simulated on a serial) 86 560.33 B
1.74 0.28 (machine.   Unfortunately) 86 547.33 B
1.74 0.28 (, conver) 206.96 547.33 B
1.74 0.28 (gence to a stable con\336guration is no longer guaranteed.) 246.09 547.33 B
0.42 0.28 (Thus the network can fall into a local minimum involving a group of unstable states among) 86 534.33 B
-0.12 0.28 (which it will oscillate. In practice, however) 86 521.33 B
-0.12 0.28 (, if the network fails to conver) 287.64 521.33 B
-0.12 0.28 (ge after some num-) 428.27 521.33 B
0.28 (ber of neuron state transitions, it can simply be stopped and started over) 86 508.33 S
0.28 (.) 421.55 508.33 S
0.42 0.28 (T) 104 495.33 B
0.42 0.28 (o illustrate the network architecture and updating scheme, let us consider how the net-) 110.22 495.33 B
0.48 0.28 (work is used to solve binary constraint satisfaction problems. A problem consists of n vari-) 86 482.33 B
3 0.28 (ables,) 86 469.33 B
3 0.28 (\311) 130.33 469.33 B
3 0.28 (, with domains) 152.94 469.33 B
3 0.28 (\311) 246.15 469.33 B
3 0.28 (, and a set of binary constraints. Each constraint) 269.75 469.33 B
0.91 0.28 ( is a subset of) 132.25 456.33 B
0.91 0.28 ( specifying incompatible values for a pair of variables. The) 233.95 456.33 B
0.03 0.28 (goal is to \336nd an assignment for each of the variables which satis\336es the constraints. \050In this) 86 443.33 B
0.97 0.28 (paper we only consider the task of \336nding a single solution, rather than that of \336nding all) 86 430.33 B
0.46 0.28 (solutions.\051 T) 86 417.33 B
0.46 0.28 (o solve a CSP using the network, each variable is represented by a separate set) 144.81 417.33 B
0.18 0.28 (of neurons, one neuron for each of the variable's possible values. Each neuron is either \322on\323) 86 404.33 B
1.07 0.28 (or \322of) 86 391.33 B
1.07 0.28 (f\323, and in a solution state, every variable will have exactly one of its corresponding) 114.45 391.33 B
0.46 0.28 (neurons \322on\323, representing the value of that variable. Constraints are represented by inhibi-) 86 378.33 B
0.55 0.28 (tory \050i.e., negatively weighted\051 connections between the neurons. T) 86 365.33 B
0.55 0.28 (o insure that every vari-) 403.99 365.33 B
1.94 0.28 (able is assigned a value, there is a guard neuron for each set of neurons representing a) 86 352.33 B
0.25 0.28 (variable; if no neuron in the set is on, the guard neuron will provide an excitatory input that) 86 339.33 B
0.57 0.28 (is lar) 86 326.33 B
0.57 0.28 (ge enough to turn one on. \050Because of the way the connection weights are set up, it is) 109.69 326.33 B
0.64 0.28 (unlikely that the guard neuron will turn on more than one neuron.\051 The network is updated) 86 313.33 B
0.69 0.28 (on each cycle by randomly picking a set of neurons that represents a variable, and \337ipping) 86 300.33 B
0.25 0.28 (the state of the neuron in that set whose input is) 86 287.33 B
2 F
0.25 0.28 (most inconsistent) 314.9 287.33 B
0 F
0.25 0.28 ( with its current output \050if) 395.82 287.33 B
0.28 (any\051. When all neurons\325 states are consistent with their input, a solution is achieved.) 86 274.33 S
0.35 0.28 (T) 104 261.33 B
0.35 0.28 (o solve the) 110.22 261.33 B
0.35 0.28 (-queens problem, for example, each of the) 171.41 261.33 B
0.35 0.28 ( board positions is repre-) 400.22 261.33 B
0.32 0.28 (sented by a neuron whose output is either one or zero depending on whether a queen is cur-) 86 248.33 B
1.18 0.28 (rently placed in that position or not. \050Note that this is a local representation rather than a) 86 235.33 B
2.05 0.28 (distributed representation of the board.\051 If two board positions are inconsistent, then an) 86 222.33 B
1.37 0.28 (inhibiting connection exists between the corresponding two neurons. For example, all the) 86 209.33 B
0.18 0.28 (neurons in a column will inhibit each other) 86 196.33 B
0.18 0.28 (, representing the constraint that two queens can-) 287.56 196.33 B
0.75 0.28 (not be in the same column. For each row) 86 183.34 B
0.75 0.28 (, there is a guard neuron connected to each of the) 281.09 183.34 B
0.69 0.28 (neurons in that row which gives the neurons in the row a lar) 86 170.34 B
0.69 0.28 (ge excitatory input, enough so) 374.24 170.34 B
-0.25 0.28 (that at least one neuron in the row will turn on. The guard neurons thus enforce the constraint) 86 157.34 B
0.3 0.28 (that one queen in each row must be on. As described above, the network is updated on each) 86 144.34 B
-0.04 0.28 (cycle by randomly picking a row and \337ipping the state of the neuron in that row whose input) 86 131.34 B
0.53 0.28 (is most inconsistent with its current output. A solution is realized when the output of every) 86 118.34 B
0.28 (neuron is consistent with its input.) 86 105.34 S
475.13 687.48 481.63 697.49 C
2 9 Q
0 X
0 K
(n) 476.14 690.33 T
0 0 612 792 C
366.53 674.48 373.03 684.49 C
2 9 Q
0 X
0 K
(n) 367.54 677.33 T
0 0 612 792 C
103.91 661.48 110.41 671.49 C
2 9 Q
0 X
0 K
(n) 104.91 664.33 T
0 0 612 792 C
177.18 660.86 203.77 673.54 C
2 12 Q
0 X
0 K
(n) 178.19 664.33 T
(n) 196.77 664.33 T
3 F
(\264) 187.18 664.33 T
0 0 612 792 C
118.99 463.69 130.33 476.49 C
2 9 Q
0 X
0 K
(X) 120 469.33 T
0 7 Q
(1) 125.83 466.22 T
0 0 612 792 C
141.6 463.76 152.94 476.49 C
2 9 Q
0 X
0 K
(X) 142.6 469.33 T
2 7 Q
(n) 148.44 466.2 T
0 0 612 792 C
233.8 463.69 246.15 476.49 C
2 9 Q
0 X
0 K
(D) 234.81 469.33 T
0 7 Q
(1) 241.65 466.22 T
0 0 612 792 C
257.41 463.76 269.75 476.49 C
2 9 Q
0 X
0 K
(D) 258.42 469.33 T
2 7 Q
(n) 265.25 466.2 T
0 0 612 792 C
86 450.76 132.25 463.49 C
2 9 Q
0 X
0 K
(C) 87.02 456.33 T
3 F
(a) 93.54 456.33 T
2 F
(X) 105.13 456.33 T
2 7 Q
(i) 110.97 453.2 T
2 9 Q
(X) 117.41 456.33 T
2 7 Q
(k) 123.25 453.2 T
3 9 Q
(,) 112.91 456.33 T
(\050) 101.25 456.33 T
(\051) 126.74 456.33 T
0 0 612 792 C
203.77 450.76 233.95 463.49 C
2 9 Q
0 X
0 K
(D) 204.79 456.33 T
2 7 Q
(j) 211.62 453.2 T
2 9 Q
(D) 223 456.33 T
2 7 Q
(k) 229.83 453.2 T
3 9 Q
(\264) 215.81 456.33 T
0 0 612 792 C
164.91 258.48 171.41 268.49 C
2 9 Q
0 X
0 K
(n) 165.91 261.33 T
0 0 612 792 C
373.64 257.86 400.22 270.54 C
2 12 Q
0 X
0 K
(n) 374.64 261.33 T
(n) 393.22 261.33 T
3 F
(\264) 383.64 261.33 T
0 0 612 792 C
FMENDPAGE
%%EndPage: "27" 4
%%Page: "28" 4
612 792 0 FMBEGINPAGE
0 10 Q
0 X
0 K
0.5 (M) 224.33 745.33 S
0 7 Q
0.35 (INTON) 233.71 745.33 S
0 10 Q
0.5 (, P) 257.2 745.33 S
0 7 Q
0.35 (HILIPS) 269.25 745.33 S
0 10 Q
0.5 (, J) 293.09 745.33 S
0 7 Q
0.35 (OHNSTON) 303.48 745.33 S
0 10 Q
0.5 (, & L) 339.31 745.33 S
0 7 Q
0.35 (AIRD) 363.19 745.33 S
0 10 Q
0.5 (28) 297.5 57.33 S
1 12 Q
(3.) 86 689.67 T
(Why does the GDS Network Perform So W) 104 689.67 T
(ell?) 324.86 689.67 T
0 11 Q
0.62 0.28 (Our analysis of the GDS network was motivated by the following question: \322Why does the) 86 671.33 B
0.38 0.28 (network perform so much better than traditional backtracking methods on certain tasks''? In) 86 658.33 B
0.22 0.28 (particular) 86 645.33 B
0.22 0.28 (, we were intrigued by the results on the) 130.41 645.33 B
0.22 0.28 (-queens problem, since this problem has) 329.21 645.33 B
-0.26 0.28 (received considerable attention from previous researchers. For) 86 632.33 B
-0.26 0.28 (-queens, Adorf and Johnston) 385.03 632.33 B
-0.03 0.28 (found empirically that the network requires a linear number of transitions to conver) 86 619.33 B
-0.03 0.28 (ge. Since) 475.28 619.33 B
0.72 0.28 (each transition requires linear time, the expected \050empirical\051 time for the network to \336nd a) 86 606.33 B
-0.22 0.28 (solution is) 86 593.33 B
-0.22 0.28 (. T) 164.74 593.33 B
-0.22 0.28 (o check this behavior) 176.79 593.33 B
-0.22 0.28 (, Johnston and Adorf ran experiments with) 275.13 593.33 B
-0.22 0.28 ( as high) 482.06 593.33 B
0.28 (as 1024,) 86 580.33 S
0 9 Q
0.22 (1) 124.82 584.73 S
0 11 Q
0.28 (at which point memory limitations became a problem.) 129.54 580.33 S
1 F
(3.1) 86 556.33 T
(Nonsystematic Sear) 113 556.33 T
(ch Hypothesis) 205.25 556.33 T
0 F
0.41 0.28 (Initially) 86 539.33 B
0.41 0.28 (, we hypothesized that the network's advantage came from the nonsystematic nature) 122.55 539.33 B
-0.18 0.28 (of its search, as compared to the systematic or) 86 526.33 B
-0.18 0.28 (ganization inherent in depth-\336rst backtracking.) 299.57 526.33 B
1.71 0.28 (There are two potential problems associated with systematic depth-\336rst search. First, the) 86 513.33 B
0.72 0.28 (search space may be or) 86 500.33 B
0.72 0.28 (ganized in such a way that poorer choices are explored \336rst at each) 196.6 500.33 B
0.58 0.28 (branch point. For instance, in the) 86 487.33 B
0.58 0.28 (-queens problem, depth-\336rst search tends to \336nd a solu-) 253.29 487.33 B
0.49 0.28 (tion more quickly when the \336rst queen is placed in the center of the \336rst row rather than in) 86 474.33 B
-0.2 0.28 (the corner; apparently this occurs because there are more solutions with the queen in the cen-) 86 461.33 B
0 0.28 (ter than with the queen in the corner) 86 448.33 B
0 0.28 (. Nevertheless, most naive algorithms tend to start in the) 254.55 448.33 B
0.6 0.28 (corner simply because humans \336nd it more natural to program that way) 86 435.33 B
0.6 0.28 (. However) 424.53 435.33 B
0.6 0.28 (, this fact) 472.92 435.33 B
1.28 0.28 (by itself does not explain why nonsystematic search would work so well for) 86 422.33 B
1.28 0.28 (-queens. A) 466.37 422.33 B
0.26 0.28 (backtracking program that randomly orders rows \050and columns within rows\051 performs much) 86 409.33 B
0.28 (better than the naive method, but still performs poorly relative to the GDS network.) 86 396.33 S
0.28 (Figure) 156.14 187.33 S
0.28 (1: Solutions Clustered vs. Solutions Evenly Distributed) 189.49 187.33 S
-0.16 0.28 (The second potential problem with depth-\336rst search is more signi\336cant and more subtle.) 104 163.33 B
0.31 0.28 (As illustrated by Figure) 86 150.33 B
0.31 0.28 (1, a depth-\336rst search can be a disadvantage when solutions are not) 200.6 150.33 B
86 120.67 518 135.67 C
86 126.67 230 126.67 2 L
0.5 H
2 Z
0 X
0 K
N
0 0 612 792 C
0 9 Q
0 X
0 K
0.03 0.22 (1. The network, which is programmed in Lisp, requires approximately 1) 86 114.67 B
0.03 0.22 (1 minutes to solve the 1024 queens prob-) 360.79 114.67 B
0.26 0.22 (lem on a TI Explorer II. For lar) 95 103.67 B
0.26 0.22 (ger problems, memory becomes a limiting factor because the network requires) 216.2 103.67 B
0.64 0.22 (approximately) 95 92.67 B
0.64 0.22 ( space. \050Although the number of connections is actually) 180.6 92.67 B
0.64 0.22 (, some connections are) 429.27 92.67 B
0.22 (computed dynamically rather than stored\051.) 95 81.67 S
322.71 642.48 329.21 652.49 C
2 9 Q
0 X
0 K
(n) 323.72 645.33 T
0 0 612 792 C
378.53 629.48 385.03 639.49 C
2 9 Q
0 X
0 K
(n) 379.54 632.33 T
0 0 612 792 C
137.09 589.34 164.74 603.28 C
2 9 Q
0 X
0 K
(O) 138.1 593.33 T
(n) 150.51 593.33 T
0 7 Q
(2) 155.35 597.5 T
3 9 Q
(\050) 146.62 593.33 T
(\051) 159.24 593.33 T
0 0 612 792 C
475.56 590.48 482.06 600.49 C
2 9 Q
0 X
0 K
(n) 476.56 593.33 T
0 0 612 792 C
152.95 88.67 180.6 102.61 C
2 9 Q
0 X
0 K
(O) 153.97 92.67 T
(n) 166.37 92.67 T
0 7 Q
(2) 171.21 96.83 T
3 9 Q
(\050) 162.49 92.67 T
(\051) 175.1 92.67 T
0 0 612 792 C
401.62 88.67 429.27 102.61 C
2 9 Q
0 X
0 K
(O) 402.64 92.67 T
(n) 415.04 92.67 T
0 7 Q
(3) 419.88 96.83 T
3 9 Q
(\050) 411.15 92.67 T
(\051) 423.77 92.67 T
0 0 612 792 C
246.79 484.48 253.29 494.49 C
2 9 Q
0 X
0 K
(n) 247.79 487.33 T
0 0 612 792 C
459.87 419.48 466.37 429.49 C
2 9 Q
0 X
0 K
(n) 460.88 422.33 T
0 0 612 792 C
86 76.67 518 697.67 C
86 207.67 518 379.67 C
86 76.67 518 697.67 C
0 0 612 792 C
FMENDPAGE
%%EndPage: "28" 5
%%Page: "29" 5
612 792 0 FMBEGINPAGE
0 10 Q
0 X
0 K
0.5 (M) 191.15 746.33 S
0 7 Q
0.35 (INIMIZING) 200.53 746.33 S
0 10 Q
0.5 ( C) 238.61 746.33 S
0 7 Q
0.35 (ONFLICTS:) 248.78 746.33 S
0 10 Q
0.5 ( A H) 287.26 746.33 S
0 7 Q
0.35 (EURISTIC) 308.69 746.33 S
0 10 Q
0.5 ( R) 342.94 746.33 S
0 7 Q
0.35 (EPAIR) 353.1 746.33 S
0 10 Q
0.5 ( M) 375.04 746.33 S
0 7 Q
0.35 (ETHOD) 387.42 746.33 S
0 10 Q
0.5 (29) 296.5 57.33 S
0 11 Q
0.44 0.28 (evenly distributed throughout the search space. In the tree at the left of the \336gure, the solu-) 86 690.33 B
-0.25 0.28 (tions are clustered together) 86 677.33 B
-0.25 0.28 (. In the tree on the right, the solutions are more evenly distributed.) 211.01 677.33 B
2.24 0.28 (Thus, the average distance between solutions is greater in the left tree. In a depth-\336rst) 86 664.33 B
-0.15 0.28 (search, the average time to \336nd the \336rst solution increases with the average distance between) 86 651.33 B
1.93 0.28 (solutions. Consequently depth-\336rst search performs relatively poorly in a tree where the) 86 638.33 B
-0.17 0.28 (solutions are clustered, such as that on the left \050Ginsber) 86 625.33 B
-0.17 0.28 (g & Harvey) 343.67 625.33 B
-0.17 0.28 (, 1990; Langley) 397.22 625.33 B
-0.17 0.28 (, 1992\051. In) 469.55 625.33 B
-0.02 0.28 (comparison, a search strategy which examines the leaves of the tree in random order is unaf-) 86 612.33 B
0.28 (fected by solution clustering.) 86 599.33 S
0.55 0.28 (W) 104 586.33 B
0.55 0.28 (e investigated whether this phenomenon explained the relatively poor performance of) 113.77 586.33 B
0.18 0.28 (depth-\336rst search on) 86 573.33 B
0.18 0.28 (-queens by experimenting with a randomized search algorithm, called) 191.25 573.33 B
0.24 0.28 (a Las V) 86 560.33 B
0.24 0.28 (egas algorithm \050Brassard & Bratley) 121.35 560.33 B
0.24 0.28 (, 1988\051. The algorithm begins by selecting a path) 287.17 560.33 B
-0.05 0.28 (from the root to a leaf. T) 86 547.33 B
-0.05 0.28 (o select a path, the algorithm starts at the root node and chooses one) 200.39 547.33 B
2.32 0.28 (of its children with equal probability) 86 534.33 B
2.32 0.28 (. This process continues recursively until a leaf is) 268.17 534.33 B
0.73 0.28 (encountered. If the leaf is a solution the algorithm terminates, if not, it starts over again at) 86 521.33 B
0.21 0.28 (the root and selects a path. The same path may be examined more than once, since no mem-) 86 508.33 B
0.28 (ory is maintained between successive trials.) 86 495.33 S
0.69 0.28 (The Las V) 104 482.33 B
0.69 0.28 (egas algorithm does, in fact, perform better than simple depth-\336rst search on) 153.01 482.33 B
0.87 0.28 (-queens \050Brassard & Bratley) 92.5 469.33 B
0.87 0.28 (, 1988\051. In fact, this result was already known. However) 227.22 469.33 B
0.87 0.28 (, the) 496.84 469.33 B
0.82 0.28 (performance of the Las V) 86 456.33 B
0.82 0.28 (egas algorithm is still not nearly as good as that of the GDS net-) 207.53 456.33 B
0.93 0.28 (work, and so we concluded that the systematicity hypothesis alone cannot explain the net-) 86 443.33 B
0.28 (work's behavior) 86 430.33 S
0.28 (.) 159.54 430.33 S
1 F
(3.2) 86 406.33 T
(Informedness Hypothesis) 113 406.33 T
0 F
0.01 0.28 (Our second hypothesis was that the network's search process uses information about the cur-) 86 389.33 B
-0.09 0.28 (rent assignment that is not available to a constructive backtracking program's use of an itera-) 86 376.33 B
1.27 0.28 (tive improvement strategy guides the search in a way that is not possible with a standard) 86 363.33 B
-0.22 0.28 (backtracking algorithm. W) 86 350.33 B
-0.22 0.28 (e now believe this hypothesis is correct, in that it explains why the) 209.64 350.33 B
-0.04 0.28 (network works so well. In particular) 86 337.33 B
-0.04 0.28 (, the key to the network's performance appears to be that) 254.53 337.33 B
0.91 0.28 (state transitions are made so as to reduce the number of outstanding inconsistencies in the) 86 324.33 B
0.01 0.28 (network; speci\336cally) 86 311.33 B
0.01 0.28 (, each state transition involves \337ipping the neuron whose output is most) 182.64 311.33 B
0.77 0.28 (inconsistent with its current input. From a constraint satisfaction perspective, it is as if the) 86 298.33 B
0.49 0.28 (network reassigns a value for a variable by choosing the value that violates the fewest con-) 86 285.33 B
0.28 (straints. This idea is captured by the following heuristic:) 86 272.33 S
1 10 Q
0.25 (Min-Con\337icts heuristic) 113 249 S
0 F
0.25 (:) 217.05 249 S
2 F
1.39 0.25 (Given) 113 237 B
0 F
1.39 0.25 (: A set of variables, a set of binary constraints, and an assignment specifying a) 138.12 237 B
0.25 (value for each variable.   T) 113 225 S
0.25 (wo variables con\337ict if their values violate a constraint.) 226.7 225 S
2 F
0.73 0.25 (Pr) 113 213 B
0.73 0.25 (ocedur) 123.12 213 B
0.73 0.25 (e) 152.01 213 B
0 F
0.73 0.25 (: Select a variable that is in con\337ict, and assign it a value that minimizes the) 156.7 213 B
0.25 (number of con\337icts.) 113 201 S
0 8 Q
0.2 (2) 197.98 205 S
0 10 Q
0.25 ( \050Break ties randomly) 202.17 201 S
0.25 (.\051) 293.65 201 S
0 11 Q
1.23 0.28 (W) 104 177.33 B
1.23 0.28 (e have found that the network's behavior can be approximated by asymbolic system) 113.77 177.33 B
-0.16 0.28 (that uses the min-con\337icts heuristic for hill climbing. The hill-climbing system starts with an) 86 164.33 B
1.49 0.28 (initial assignment generated in a preprocessing phase. At each choice point, the heuristic) 86 151.33 B
86 131.67 518 146.67 C
86 137.67 230 137.67 2 L
0.5 H
2 Z
0 X
0 K
N
0 0 612 792 C
0 9 Q
0 X
0 K
0.34 0.22 (2. In general, the heuristic attempts to minimize the number of other variables that will need to be repaired. For) 86 125.67 B
0.68 0.22 (binary CSPs, this corresponds to minimizing the number of con\337icting variables. For general CSPs, where a) 95 114.67 B
0.06 0.22 (single constraint may involve several variables, the exact method of counting the number of variables that will) 95 103.67 B
0.4 0.22 (need to be repaired depends on the particular constraint. The space telescope scheduling problem is a general) 95 92.67 B
0.22 (CSP) 95 81.67 S
0.22 (, whereas the other tasks described in this paper are binary CSPs.) 110.67 81.67 S
184.75 570.48 191.25 580.49 C
2 9 Q
0 X
0 K
(n) 185.76 573.33 T
0 0 612 792 C
86 466.48 92.5 476.49 C
2 9 Q
0 X
0 K
(n) 87 469.33 T
0 0 612 792 C
FMENDPAGE
%%EndPage: "29" 6
%%Page: "30" 6
612 792 0 FMBEGINPAGE
0 10 Q
0 X
0 K
0.5 (M) 224.33 745.33 S
0 7 Q
0.35 (INTON) 233.71 745.33 S
0 10 Q
0.5 (, P) 257.2 745.33 S
0 7 Q
0.35 (HILIPS) 269.25 745.33 S
0 10 Q
0.5 (, J) 293.09 745.33 S
0 7 Q
0.35 (OHNSTON) 303.48 745.33 S
0 10 Q
0.5 (, & L) 339.31 745.33 S
0 7 Q
0.35 (AIRD) 363.19 745.33 S
0 10 Q
0.5 (30) 297.5 57.33 S
0 11 Q
1.62 0.28 (chooses a variable that is currently in con\337ict and reassigns its value, until a solution is) 86 690.33 B
1.45 0.28 (found. The system thus searches the space of possible assignments, favoring assignments) 86 677.33 B
0.22 0.28 (with fewer total con\337icts. Of course, the hill-climbing system can become \322stuck'' in a local) 86 664.33 B
-0.05 0.28 (maximum, in the same way that the network may become \322stuck\323 in a local minimum. In the) 86 651.33 B
2.65 0.28 (next section we present empirical evidence to support our claim that the min-con\337icts) 86 638.33 B
0.28 (approach can account for the network's ef) 86 625.33 S
0.28 (fectiveness.) 280.26 625.33 S
0.54 0.28 (There are two aspects of the min-con\337icts hill-climbing method that distinguish it from) 104 612.33 B
1.85 0.28 (standard CSP algorithms. First, instead of incrementally constructing a consistent partial) 86 599.33 B
2.23 0.28 (assignment, the min-con\337icts method repairs a complete but inconsistent assignment by) 86 586.33 B
0.2 0.28 (reducing inconsistencies. Thus, it uses information about the current assignment to guide its) 86 573.33 B
0.75 0.28 (search that is not available to a standard backtracking algorithm. Second, the use of a hill-) 86 560.33 B
0.28 (climbing strategy rather than a backtracking strategy produces a dif) 86 547.33 S
0.28 (ferent style of search.) 400.76 547.33 S
-0.14 0.28 (Extracting the method from the network enables us to tease apart and experiment with its) 104 534.33 B
0.69 0.28 (dif) 86 521.33 B
0.69 0.28 (ferent components. In particular) 98.83 521.33 B
0.69 0.28 (, the idea of repairing an inconsistent assignment can be) 250.21 521.33 B
0.84 0.28 (used with a variety of dif) 86 508.33 B
0.84 0.28 (ferent search strategies in addition to hill climbing. For example,) 207.31 508.33 B
1.59 0.28 (we can backtrack through the space of possible repairs, rather than using a hill-climbing) 86 495.33 B
0.31 0.28 (strategy) 86 482.33 B
0.31 0.28 (, as follows. Given an initial assignment generated in a preprocessing phase, we can) 122.27 482.33 B
0.12 0.28 (employ the min-con\337icts heuristic to order the choice of variables and values to consider) 86 469.33 B
0.12 0.28 (, as) 501.86 469.33 B
0.11 0.28 (described in Figure) 86 456.33 B
0.11 0.28 (2. Initially) 179.29 456.33 B
0.11 0.28 (, the variables are all on a list of V) 227.77 456.33 B
0.11 0.28 (ARS-LEFT) 389.14 456.33 B
0.11 0.28 (, and as they are) 441.8 456.33 B
2.06 0.28 (repaired, they are pushed onto a list of V) 86 443.33 B
2.06 0.28 (ARS-DONE. The algorithm attempts to \336nd a) 291.74 443.33 B
0.72 0.28 (sequence of repairs, such that no variable is repaired more than once. If there is no way to) 86 430.33 B
1.67 0.28 (repair a variable in without violating a previously repaired variable \050a variable in V) 86 417.33 B
1.67 0.28 (ARS) 495.81 417.33 B
0.28 (DONE\051, the algorithm backtracks.) 86 404.33 S
4 9 Q
(Procedure INFORMED-BACKTRACK \050VARS-LEFT VARS-DONE\051) 104 381.67 T
(If all variables are consistent, then solution found, STOP.) 113 370.67 T
(Let VAR = a variable in VARS-LEFT that is in conf) 113 359.67 T
(lict.) 377.23 359.67 T
(Remove VAR from VARS-LEFT.) 113 348.67 T
(Push VAR onto VARS-DONE.) 113 337.67 T
(Let VALUES = list of possible values for VAR ordered in ascending order) 113 326.67 T
-1.74 (according to number of conf) 185 315.67 P
-1.74 (licts with variables in VARS-LEFT.) 323.63 315.67 P
(For each VALUE in VALUES, until solution found:) 113 304.67 T
(If VALUE does not conf) 122 293.67 T
(lict with any variable that is in VARS-DONE,) 240.63 293.67 T
(then Assign VALUE to VAR.) 122 282.67 T
(Call INFORMED-BACKTRACK\050VARS-LEFT VARS-DONE\051) 131 271.67 T
(end if) 122 260.67 T
(end for) 113 249.67 T
(end procedure) 104 238.67 T
(Begin program) 104 216.67 T
(Let VARS-LEFT = list of all variables, each assigned an initial value.) 113 205.67 T
(Let VARS-DONE = nil) 113 194.67 T
(Call INFORMED-BACKTRACK\050VARS-LEFT VARS-DONE\051) 113 183.67 T
(End program) 104 172.67 T
0 11 Q
0.28 (Figure) 144 149.33 S
0.28 (2: Informed Backtracking Using the Min-Conflicts Heuristic) 177.36 149.33 S
0.86 0.28 (Notice that this algorithm is simply a standard backtracking algorithm augmented with) 104 125.33 B
0.51 0.28 (the min-con\337icts heuristic to order its choice of which variable and value to attend to. This) 86 112.33 B
1.79 0.28 (illustrates an important point. The backtracking repair algorithm incrementally extends a) 86 99.33 B
0.76 0.28 (consistent partial assignment \050i.e., V) 86 86.33 B
0.76 0.28 (ARS DONE\051, as does a constructive backtracking pro-) 258.26 86.33 B
FMENDPAGE
%%EndPage: "30" 7
%%Page: "31" 7
612 792 0 FMBEGINPAGE
0 10 Q
0 X
0 K
0.5 (M) 191.15 746.33 S
0 7 Q
0.35 (INIMIZING) 200.53 746.33 S
0 10 Q
0.5 ( C) 238.61 746.33 S
0 7 Q
0.35 (ONFLICTS:) 248.78 746.33 S
0 10 Q
0.5 ( A H) 287.26 746.33 S
0 7 Q
0.35 (EURISTIC) 308.69 746.33 S
0 10 Q
0.5 ( R) 342.94 746.33 S
0 7 Q
0.35 (EPAIR) 353.1 746.33 S
0 10 Q
0.5 ( M) 375.04 746.33 S
0 7 Q
0.35 (ETHOD) 387.42 746.33 S
0 10 Q
0.5 (31) 296.5 57.33 S
0 11 Q
-0.23 0.28 (gram, but in addition, uses information from the initial assignment \050i.e., V) 86 690.33 B
-0.23 0.28 (ARS LEFT\051 to bias) 428.26 690.33 B
-0.08 0.28 (its search. Thus, it is a type of informed backtracking. W) 86 677.33 B
-0.08 0.28 (e still characterize it as repair) 350.17 677.33 B
-0.08 0.28 (-based) 487.68 677.33 B
0.28 (method since its search is guided by a complete, inconsistent assignment.) 86 664.33 S
1 F
(3.2.1) 86 640.33 T
(Repair) 122 640.33 T
(-Based Sear) 153.94 640.33 T
(ch Strategies) 209.58 640.33 T
0 F
-0.16 0.28 (\050This is an example of a third level section.\051 Extracting the method from the network enables) 86 623.33 B
1.67 0.28 (us to tease apart and experiment with its dif) 86 610.33 B
1.67 0.28 (ferent components. In particular) 303.2 610.33 B
1.67 0.28 (, the idea of) 457.53 610.33 B
0.11 0.28 (repairing an inconsistent assignment can be used with a variety of dif) 86 597.33 B
0.11 0.28 (ferent search strategies) 410.51 597.33 B
1.17 0.28 (in addition to hill climbing. For example, we can backtrack through the space of possible) 86 584.33 B
1.38 0.28 (repairs, rather than using a hill-climbing strategy) 86 571.33 B
1.38 0.28 (, as follows. Given an initial assignment) 322.08 571.33 B
2.37 0.28 (generated in a preprocessing phase, we can employ min-con\337icts heuristic to order the) 86 558.33 B
0.89 0.28 (choice of variables and values to consider) 86 545.33 B
0.89 0.28 (, as described in Figure) 286.12 545.33 B
0.89 0.28 (2. Initially) 401.52 545.33 B
0.89 0.28 (, the variables) 450.77 545.33 B
1.54 0.28 (are all on a list of) 86 532.33 B
4 F
3.5 0.28 (VARS-LEFT) 180.34 532.33 B
0 F
1.54 0.28 (, and as they are repaired, they are pushed onto a list of) 241.33 532.33 B
4 F
1.15 0.28 (VARS-DONE) 86 519.33 B
0 F
0.5 0.28 (. The algorithm attempts to \336nd a sequence of repairs, such that no variable is) 147.8 519.33 B
0.18 0.28 (repaired more than once. If there is no way to repair a variable in) 86 506.33 B
4 F
0.41 0.28 (VARS-LEFT) 395.5 506.33 B
0 F
0.18 0.28 ( without vio-) 457.3 506.33 B
0.28 (lating a previously repaired variable \050a variable in) 86 493.33 S
4 F
0.28 (VARS-DONE) 322.68 493.33 S
0 F
0.28 (\051, the algorithm backtracks.) 384.48 493.33 S
1 12 Q
(4.) 86 467.67 T
(Experimental Results) 104 467.67 T
0 11 Q
0.28 ([Section Omitted]) 86 449.33 S
1 12 Q
(5.) 86 423.67 T
(A Theor) 104 423.67 T
(etical Model) 146.76 423.67 T
0 11 Q
0.28 ([Section Omitted]) 86 405.33 S
1 12 Q
(6.) 86 379.67 T
(Discussion) 104 379.67 T
0 11 Q
0.28 ([Section Omitted]) 86 361.33 S
1 12 Q
(Acknowledgments) 86 335.67 T
0 11 Q
0.01 0.28 (The authors wish to thank Hans-Martin T) 86 317.33 B
0.01 0.28 (arif) 278.48 317.33 B
0.01 0.28 (f, Don Rosenthal, Richard Fernier) 294.63 317.33 B
0.01 0.28 (, Peter Chees-) 452.81 317.33 B
0.21 0.28 (man and Monte Zwieback for their assistance and advice. W) 86 304.33 B
0.21 0.28 (e also thank Ron Music and our) 368.73 304.33 B
0.06 0.28 (anonymous reviewers for their comments. The Space T) 86 291.33 B
0.06 0.28 (elescope Science Institute is operated) 343.16 291.33 B
0.28 (by the Association of Universities for Research in Astronomy for NASA.) 86 278.33 S
1 12 Q
0.3 (Appendix A.) 86 252.67 S
0.3 (Pr) 158 252.67 S
0.3 (obability Distributions for N-Queens) 171.04 252.67 S
0 11 Q
0.28 ([Appendix Omitted]) 86 234.33 S
1 12 Q
(Refer) 86 208.67 T
(ences) 114.41 208.67 T
0 11 Q
0.28 (Interbred, M. \0501973\051.) 86 184.33 S
2 F
0.28 (Cluster analysis for applications) 187.85 184.33 S
0 F
0.28 (. New Y) 340.68 184.33 S
0.28 (ork: Academic Press.) 378.42 184.33 S
0.32 0.28 (Blaming, D., & Hit, E. \0501988\051. Observational learning from internal feedback: A simulation) 86 160.33 B
0.28 (of an adaptive learning method.) 104 147.33 S
2 F
0.28 (Cognitive Science) 254.98 147.33 S
0 F
0.28 (,) 338.68 147.33 S
2 F
0.28 (12) 344.72 147.33 S
0 F
0.28 (, 587\320625.) 356.26 147.33 S
0.42 0.28 (Detrain, R., Janis, A., Steinber) 86 123.33 B
0.42 0.28 (g, W) 230.54 123.33 B
0.42 0.28 (., Uplifters, M., Schmidt, J., Sandhi, S., Guppy) 252.41 123.33 B
0.42 0.28 (, K., Lee,) 473.53 123.33 B
0.35 0.28 (S., & Freeholder) 104 110.33 B
0.35 0.28 (, V) 181.89 110.33 B
0.35 0.28 (. \0501989\051. International application of a new probability algorithm for) 195.07 110.33 B
0.28 (the diagnosis of coronary artery disease.) 104 97.33 S
2 F
0.28 (American Journal of Car) 295.25 97.33 S
0.28 (diology) 411.94 97.33 S
0 F
0.28 (,) 446.11 97.33 S
2 F
0.28 (64) 452.15 97.33 S
0 F
0.28 (, 304\320310.) 463.69 97.33 S
FMENDPAGE
%%EndPage: "31" 8
%%Page: "32" 8
612 792 0 FMBEGINPAGE
0 10 Q
0 X
0 K
0.5 (M) 224.33 745.33 S
0 7 Q
0.35 (INTON) 233.71 745.33 S
0 10 Q
0.5 (, P) 257.2 745.33 S
0 7 Q
0.35 (HILIPS) 269.25 745.33 S
0 10 Q
0.5 (, J) 293.09 745.33 S
0 7 Q
0.35 (OHNSTON) 303.48 745.33 S
0 10 Q
0.5 (, & L) 339.31 745.33 S
0 7 Q
0.35 (AIRD) 363.19 745.33 S
0 10 Q
0.5 (32) 297.5 57.33 S
0 11 Q
1.62 0.28 (Fisher) 86 690.33 B
1.62 0.28 (, D. \0501987\051. Knowledge acquisition via incremental conceptual clustering.) 114.68 690.33 B
2 F
1.62 0.28 (Machine) 477.63 690.33 B
0.28 (Learning) 104 677.33 S
0 F
0.28 (,) 146.49 677.33 S
2 F
0.28 (2) 152.53 677.33 S
0 F
0.28 (, 139\320172.) 158.3 677.33 S
1.38 0.28 (Gennari, J. H. \0501990\051.) 86 653.33 B
2 F
1.38 0.28 (An experimental study of concept formation) 196.68 653.33 B
0 F
1.38 0.28 ( \050Doctoral dissertation,) 407.65 653.33 B
0.85 0.28 (also T) 104 640.33 B
0.85 0.28 (echnical Report 90-26\051. Irvine: University of California, Department of Informa-) 132.89 640.33 B
0.28 (tion and Computer Science.) 104 627.33 S
0.71 0.28 (Gennari, J. H., Langley) 86 603.33 B
0.71 0.28 (, P) 196.58 603.33 B
0.71 0.28 (., & Fisher) 208.5 603.33 B
0.71 0.28 (, D. \0501989\051. Models of incremental concept formation.) 259.51 603.33 B
2 F
0.28 (Arti\336cial Intelligence) 104 590.33 S
0 F
0.28 (,) 203.73 590.33 S
2 F
0.28 (40) 209.77 590.33 S
0 F
0.28 (, 1) 221.31 590.33 S
0.28 (1\32061.) 232.71 590.33 S
0.91 0.28 (Gluck, M., & Corter) 86 566.33 B
0.91 0.28 (, J. \0501985\051. Information, uncertainty and the utility of categories.) 183.22 566.33 B
2 F
0.91 0.28 (Pr) 497.17 566.33 B
0.91 0.28 (o-) 508.3 566.33 B
1 0.28 (ceedings of the Seventh Annual Confer) 104 553.33 B
1 0.28 (ence of the Cognitive Science Society) 289.36 553.33 B
0 F
1 0.28 ( \050pp. 283\320) 468.39 553.33 B
0.28 (287\051. Irvine, CA: Lawrence Erlbaum.) 104 540.33 S
0.87 0.28 (Iba, W) 86 516.33 B
0.87 0.28 (., & Gennari, J. H. \050in press\051. Learning to recognize movements. In D. Fisher & M.) 117.41 516.33 B
0.68 0.28 (Pazzani \050Eds.\051,) 104 503.33 B
2 F
0.68 0.28 (Computational appr) 178.7 503.33 B
0.68 0.28 (oaches to concept formation) 273.35 503.33 B
0 F
0.68 0.28 (. San Mateo, CA: Mor-) 407.6 503.33 B
0.28 (gan Kaufmann.) 104 490.33 S
0.57 0.28 (Michalski, R. S., & Stepp, R. \0501983\051. Learning from observation: Conceptual clustering. In) 86 466.33 B
0.26 0.28 (R. S. Michalski, J. G. Carbonell, & T) 104 453.33 B
0.26 0.28 (. M. Mitchell \050Ends.\051,) 279.08 453.33 B
2 F
0.26 0.28 (Machine learning: An arti\336-) 384.71 453.33 B
0.28 (cial intelligence appr) 104 440.33 S
0.28 (oach) 203.63 440.33 S
0 F
0.28 (. San Mateo, CA: Mor) 226.09 440.33 S
0.28 (gan Kaufmann.) 329.65 440.33 S
0.28 (Quinlan, J. R. \0501986\051. Induction of decision trees.) 86 416.33 S
2 F
0.28 (Machine Learning) 320.91 416.33 S
0 F
0.28 (,) 406.79 416.33 S
2 F
0.28 (1) 412.83 416.33 S
0 F
0.28 (, 81\320106.) 418.6 416.33 S
0.65 0.28 (Schneider) 86 392.33 B
0.65 0.28 (, W) 131.97 392.33 B
0.65 0.28 (., Dames, S. T) 148.3 392.33 B
0.65 0.28 (., & Shivering, R. M. \0501984\051. Automatic and control processing) 215.85 392.33 B
1.32 0.28 (and attention. In R. Parathormone & D. R. Davies \050Ends.\051,) 104 379.33 B
2 F
1.32 0.28 (V) 393.09 379.33 B
1.32 0.28 (arieties of attention) 398.86 379.33 B
0 F
1.32 0.28 (. San) 493.34 379.33 B
0.28 (Diego, CA: Academic Press.) 104 366.33 S
FMENDPAGE
%%EndPage: "32" 9
%%Trailer
%%BoundingBox: 0 0 612 792
%%Pages: 8 1
%%DocumentFonts: Times-Roman
%%+ Times-Bold
%%+ Times-Italic
%%+ Symbol
%%+ Courier
